{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Sofia Tkachenko\n",
    "- Hulk\n",
    "- Iron Man\n",
    "- Thor\n",
    "- Wasp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Include a specific, clear data science question.\n",
    "-  Make sure what you're measuring (variables) to answer the question is clear\n",
    "\n",
    "What is your research question? Include the specific question you're setting out to answer. This question should be specific, answerable with data, and clear. A general question with specific subquestions is permitted. (1-2 sentences)\n",
    "\n",
    "Since 2020, how does the number of anti-LGBT laws passed per year and their severity (e.g. number of affected individuals) impact the mental health (e.g. risk of depression, suicide, PTSD) of the general population within each U.S. state when controlling for factors such as poverty and mental health resource availability? Additionally, is there a differential effect on mental health outcomes across age groups and other demographics, such as socioeconomic status, race, and age?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout American history, the LGBTQ+ community has fought for their rights amidst challenges from the government, both nationally and on a state-by-state basis. Recently, anti-LGBTQ laws have had a resurgence throughout the country. These laws come in many different forms, from barriers to accurate ID information to restricting school curriculum. Some states, like Florida, have even criminalized gender-affirming care, which can have dangerous consequences for transgender individuals. This led our group to wonder if surges in this legislation has an effect on the general population in each U.S. state.\n",
    "\n",
    "Charities such as the Trevor Project, which is commited to helping LGBTQ youth in the midst of crises, have studied negative impacts anti LGBTQ legislation can have on LGBT youth. In this particular survey <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1), 716 LGTBQ youth aged 13-24 were polled about developments in anti-LGBTQ legislation. Notably, 86% of transgender youth reported struggling more with their mental health after discussion of anti-trans bills began circulating. 75% of LGBTQ youth also report experiencing stress and anxiety over threats of violence against LGBTQ spaces, which can be related to the rise in anti-LGBTQ legislation. <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) This is a good starting point, as it illustrates what the impact of these laws can look like on LGBTQ youth, an especially vulnerable and relevant population for this question. Unfortunately, there is a severe lack of information on LGBTQ mental health data by state. From these surveys, we can only surmise that these laws are not inconsequential.\n",
    "\n",
    "The Human Rights Campaign has been tracking the types of legislation each state passes and supports <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). It seems that states with anti-LGBTQ legislation tend to also fall short in other aspects of human rights. For example, Alabama doesn't support transgender healthcare while also failing to provide support for housing, hate crimes, education, and more. Because of this, we believe it's reasonable that anti-LGBTQ legislation may be tied to a broader lack of human rights in some states. Could this effect be seen in the general population?\n",
    "\n",
    "Certain human rights groups, such as the ACLU, report on congressional bills that affect human rights, making this data available to the public <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). This will help us in our analysis, as we are able to see which states have put the most effort into restricting LGBTQ rights. Specifically, we can observe which bills have been introduced, passed into law, or defeated in each state. For example, Arizona is currently advancing a bill that will mandate forced outing of LGBTQ students to parents. As it stands, more than 300 anti-LGBTQ bills are advancing in their respective state sessions. Less than 20 have been defeated <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3).\n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Sylvester, E. (2023, September 22). New poll emphasizes negative impacts of Anti-LGBTQ policies on LGBTQ youth. The Trevor Project. https://www.thetrevorproject.org/blog/new-poll-emphasizes-negative-impacts-of-anti-lgbtq-policies-on-lgbtq-youth/\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Laws and Legislation: State Scorecards. (2023). Human Rights Campaign. https://www.hrc.org/resources/state-scorecards\n",
    "\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Mapping attacks on LGBTQ rights in U.S. state legislatures in 2024 | American Civil Liberties Union. (2024, February 9). American Civil Liberties Union. https://www.aclu.org/legislative-attacks-on-lgbtq-rights-2024?impact=#overview\n",
    "\n",
    "\n",
    "- Include a general introduction to your topic\n",
    "- Include explanation of what work has been done previously\n",
    "- Include citations or links to previous work\n",
    "\n",
    "This section will present the background and context of your topic and question in a few paragraphs. Include a general introduction to your topic and then describe what information you currently know about the topic after doing your initial research. Include references to other projects who have asked similar questions or approached similar problems. Explain what others have learned in their projects.\n",
    "\n",
    "Find some relevant prior work, and reference those sources, summarizing what each did and what they learned. Even if you think you have a totally novel question, find the most similar prior work that you can and discuss how it relates to your project.\n",
    "\n",
    "References can be research publications, but they need not be. Blogs, GitHub repositories, company websites, etc., are all viable references if they are relevant to your project. It must be clear which information comes from which references. (2-3 paragraphs, including at least 2 references)\n",
    "\n",
    " **Use inline citation through HTML footnotes to specify which references support which statements** \n",
    "\n",
    "For example: After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Use a minimum of 2 or 3 citations, but we prefer more.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) You need enough to fully explain and back up important facts. \n",
    "\n",
    "Note that if you click a footnote number in the paragraph above it will transport you to the proper entry in the footnotes list below.  And if you click the ^ in the footnote entry, it will return you to the place in the main text where the footnote is made.\n",
    "\n",
    "To understand the HTML here, `<a name=\"#...\"> </a>` is a tag that allows you produce a named reference for a given location.  Markdown has the construciton `[text with hyperlink](#named reference)` that will produce a clickable link that transports you the named reference.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include your team's hypothesis\n",
    "- Ensure that this hypothesis is clear to readers\n",
    "- Explain why you think this will be the outcome (what was your thinking?)\n",
    "\n",
    "What is your main hypothesis/predictions about what the answer to your question is? Briefly explain your thinking. (2-3 sentences)\n",
    "\n",
    "We hypothesize that there will be a small but significant effect between the amount of anti-LGBTQ legislation in each state per year and the mental health outcomes of the general population of that state. That is, states that attempt to pass more anti-LGBTQ legislation will see worse mental health outcomes in their population over the years 2020-2023 when controlling for factors such as poverty level and mental health resource accessibility. We hypothesize that this effect will be stronger among non-white individuals, youth, as well as those of lower socioeconomic status.\n",
    "\n",
    "Most people aren't part of the LGBTQ community, but anti-LGBTQ legislation reflects a broader anti-human-rights agenda that affects a larger portion of the population. Ideally, we would answer this question for the LGBTQ community itself, but there is an unfortunate lack of data on LGBTQ mental health outcomes by state. Nonetheless, states that are more aggressively anti-LGBTQ might be more aggressively anti-human-rights in general, which could impact the well-being of the general population more than one expects. Additionally, those who are nonwhite may experience racism, which could exarcerbate their mental health. Youths may also be more affected by anti-LGBTQ laws, since many anti-LGBTQ laws are directed towards schools. Those of lower socioeconomic status may also be impacted disproportionately, since they likely don't have funds to change their residence to a more inclusive state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "\n",
    "#### Dataset #1: Mental Health Risk Assessments (2020-2023)\n",
    "  - https://mhanational.org/mhamapping/mha-state-county-data\n",
    "  - 204 observations after current wrangling stage (will include more once age and racial subgroups are accounted for)\n",
    "  - 9 variables after current wrangling stage\n",
    "    - State, Year, Group Type (age, race, etc.), Total State Population, and # of people per 100K at risk of 5 different mental health issues\n",
    "\n",
    "This data is sourced from Mental Health America, a group dedicated to tracking mental health data across the United States. Data was obtained from 5 million mental health screens taken by U.S. users from 2020-2023. Using these screens, MHA analyzed the number of people in each state that were at risk of/reporting various mental health issues. From each state, there is data on the number of people per 100K of the population at risk of 1) depression, 2) suicide, 3) PTSD, 4) trauma and 5) psychosis. Most such data are given in float format, since \"per 100K\" implies approximation. One can filter to include different age groups (youth vs. adult), racial groups, and years. \n",
    "\n",
    "This data will be one of the primary sources to answer our research question. Analyzing the proportion of people at risk in each state can help quantify the relationship between anti-LGBTQ laws being passed and the consequent behavior of mental health per state.\n",
    "\n",
    "The data is relatively clean but produces a new CSV based on each year, age, and race setting. Currently, we have only combined data across all available years (2020-2023). We have yet to consider subgroups pertaining to race and age. To wrangle this data, we dropped unneeded columns, shortened long variable (column) names, added a year identifier to make it easier to combine other datasets, and combined MHA data from years 2020-2023 via the \"concat()\" method from pandas.\n",
    "\n",
    "#### Dataset #2: Income in the Past 12 Months (Inflation-Adjusted Dollars) (2020-2022)\n",
    "  - https://data.census.gov/table?t=Income%20and%20Poverty&g=040XX00US01,02,04,05,06,08,09,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,50,51,53,54,55,56\n",
    "    - Link above is for 2022 only\n",
    "    - Filter to include all 50 U.S. states, Income and Poverty tag, and years 2020-2022\n",
    "  - 612 observations after current wrangling stage (more if each income bracket is considered separately)\n",
    "  - 6 variables after current wrangling stage\n",
    "    - Income brackets are treated as one \"variable\"\n",
    "    - State, Year, Group Type (Household, Family, Married, Nonfamily), Proportion of State in each Income Bracket (10 brackets), Mean and Median Income \n",
    "\n",
    "This data is sourced from the U.S. Census Bureau and contains information for each state about income levels. It separates information based on type of household (married, family, etc.) and income bracket, identifying the proportion of each group within each state that belongs to a particular income bracket. The dataset also summarizes mean and median income of each group.\n",
    "\n",
    "This data will be used as a control for our question, since there are many confounding factors for mental health aside from potentially anti-LGBTQ laws. According to the National Institute of Health, poverty is significantly correlated with poorer mental health outcomes <a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4). Therefore, it is necessary to use this data to control against the effect of poverty on mental health.\n",
    "\n",
    "Extensive measures had to be taken to wrangle this data, and more wrangling is likely required. Almost all data were objects (strings), so standardizing functions were applied to convert entries to floats or integers. A \"State\" and \"Year\" column were created to make it easier to combine datasets, and the \"State\" column had to extract information from a column that combined state and group-type information (e.g. Alabama Households Estimate). This column requires wrangling as it effectively contains two variables (state + group type) in one, but this may be a bit tricky since the dataset relies on breaking data down by group type, state, and income bracket. One way to resolve this would be to create a separate column for income bracket type and group type. This would decrease the amount of columns while increasing the amount of observations in the data frame, because each group-and-income-bracket pair will becomoe its own observation. The data is currently in a tidy format (see full wrangling process below) but the previously mentioned changes will also be applied.\n",
    "\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Knifton, L. and Inglis G. (Oct 2020). Poverty and mental health: policy, practice and research implications. *National Institute of Health*. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7525587/#:~:text=Poverty%20is%20both%20a%20cause,social%20stresses%2C%20stigma%20and%20trauma. \n",
    "\n",
    "##### Instructions\n",
    "\n",
    "Now write 2 - 5 sentences describing each dataset here. Include a short description of the important variables in the dataset; what the metrics and datatypes are, what concepts they may be proxies for. Include information about how you would need to wrangle/clean/preprocess the dataset\n",
    "\n",
    "Erik wrote a function to clean the dataset from being a text file into being a csv. He had to copy and paste and a lot of times, reformat the information because the formatting fell apart a bit in some places. This will allow us to use the function to make tables which have a column specifying which part of the original document the data came from, which will allow us to distinguish different types of laws that have been passed.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1: Mental Health Risk Assessments (2020-2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Group</th>\n",
       "      <th>Year</th>\n",
       "      <th>Psychotic Episodes</th>\n",
       "      <th>Trauma Survivors</th>\n",
       "      <th>Suicidal Ideation</th>\n",
       "      <th>PTSD</th>\n",
       "      <th>Severe Depression</th>\n",
       "      <th>Total Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>29.088011</td>\n",
       "      <td>53.235426</td>\n",
       "      <td>45.338408</td>\n",
       "      <td>13.730494</td>\n",
       "      <td>41.945468</td>\n",
       "      <td>5039877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>49.544613</td>\n",
       "      <td>98.133820</td>\n",
       "      <td>83.120301</td>\n",
       "      <td>25.386496</td>\n",
       "      <td>70.836512</td>\n",
       "      <td>732673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>25.411211</td>\n",
       "      <td>54.244483</td>\n",
       "      <td>47.331644</td>\n",
       "      <td>13.482097</td>\n",
       "      <td>43.895840</td>\n",
       "      <td>7276316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>26.768975</td>\n",
       "      <td>58.197734</td>\n",
       "      <td>40.087366</td>\n",
       "      <td>18.275609</td>\n",
       "      <td>39.029826</td>\n",
       "      <td>3025891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>18.698789</td>\n",
       "      <td>42.030860</td>\n",
       "      <td>41.340200</td>\n",
       "      <td>10.408321</td>\n",
       "      <td>37.298183</td>\n",
       "      <td>39237836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>18.298822</td>\n",
       "      <td>78.941741</td>\n",
       "      <td>41.284630</td>\n",
       "      <td>16.133826</td>\n",
       "      <td>37.507403</td>\n",
       "      <td>8683619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>21.783286</td>\n",
       "      <td>105.602697</td>\n",
       "      <td>45.017934</td>\n",
       "      <td>18.636526</td>\n",
       "      <td>39.713396</td>\n",
       "      <td>7785786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>26.983544</td>\n",
       "      <td>97.399890</td>\n",
       "      <td>40.954147</td>\n",
       "      <td>23.716226</td>\n",
       "      <td>40.672482</td>\n",
       "      <td>1775156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>19.668941</td>\n",
       "      <td>86.431333</td>\n",
       "      <td>40.016706</td>\n",
       "      <td>15.680847</td>\n",
       "      <td>35.264934</td>\n",
       "      <td>5892539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>20.124497</td>\n",
       "      <td>102.686534</td>\n",
       "      <td>43.345070</td>\n",
       "      <td>20.640509</td>\n",
       "      <td>42.485049</td>\n",
       "      <td>581381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            State     Group  Year  Psychotic Episodes  Trauma Survivors  \\\n",
       "0         Alabama  All Ages  2020           29.088011         53.235426   \n",
       "1          Alaska  All Ages  2020           49.544613         98.133820   \n",
       "2         Arizona  All Ages  2020           25.411211         54.244483   \n",
       "3        Arkansas  All Ages  2020           26.768975         58.197734   \n",
       "4      California  All Ages  2020           18.698789         42.030860   \n",
       "..            ...       ...   ...                 ...               ...   \n",
       "46       Virginia  All Ages  2023           18.298822         78.941741   \n",
       "47     Washington  All Ages  2023           21.783286        105.602697   \n",
       "48  West Virginia  All Ages  2023           26.983544         97.399890   \n",
       "49      Wisconsin  All Ages  2023           19.668941         86.431333   \n",
       "50        Wyoming  All Ages  2023           20.124497        102.686534   \n",
       "\n",
       "    Suicidal Ideation       PTSD  Severe Depression  Total Population  \n",
       "0           45.338408  13.730494          41.945468           5039877  \n",
       "1           83.120301  25.386496          70.836512            732673  \n",
       "2           47.331644  13.482097          43.895840           7276316  \n",
       "3           40.087366  18.275609          39.029826           3025891  \n",
       "4           41.340200  10.408321          37.298183          39237836  \n",
       "..                ...        ...                ...               ...  \n",
       "46          41.284630  16.133826          37.507403           8683619  \n",
       "47          45.017934  18.636526          39.713396           7785786  \n",
       "48          40.954147  23.716226          40.672482           1775156  \n",
       "49          40.016706  15.680847          35.264934           5892539  \n",
       "50          43.345070  20.640509          42.485049            581381  \n",
       "\n",
       "[204 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "renamer = {\n",
    "    'Age1': 'Group',\n",
    "    'Year1': 'Year',\n",
    "    'Number of People At Possible Risk for Psychotic-Like Episodes': 'Psychotic Episodes',\n",
    "    'Number of People Identifying as Trauma Survivors': 'Trauma Survivors',\n",
    "    'Number of People Reporting Frequent Suicidal Ideation': 'Suicidal Ideation',\n",
    "    'Number of People Scoring Positive for PTSD': 'PTSD',\n",
    "    'Number of People Scoring with Severe Depression': 'Severe Depression'\n",
    "}\n",
    "\n",
    "to_keep = ['State', 'Group', 'Year',\n",
    "           'Psychotic Episodes', 'Trauma Survivors',\n",
    "           'Suicidal Ideation', 'PTSD',\n",
    "           'Severe Depression', 'Total Population']\n",
    "\n",
    "mh2020 = pd.read_csv('data/full_mh_2020.csv')\n",
    "mh2020 = mh2020.rename(renamer, axis=1)\n",
    "mh2020 = mh2020[(to_keep)]\n",
    "\n",
    "mh2021 = pd.read_csv('data/full_mh_2021.csv')\n",
    "mh2021 = mh2021.rename(renamer, axis=1)\n",
    "mh2021 = mh2021[(to_keep)]\n",
    "\n",
    "mh2022 = pd.read_csv('data/full_mh_2022.csv')\n",
    "mh2022 = mh2022.rename(renamer, axis=1)\n",
    "mh2022 = mh2022[(to_keep)]\n",
    "\n",
    "mh2023 = pd.read_csv('data/full_mh_2023.csv')\n",
    "mh2023 = mh2023.rename(renamer, axis=1)\n",
    "mh2023 = mh2023[(to_keep)]\n",
    "\n",
    "combined_20_23 = pd.concat([mh2020, mh2021], axis=0)\n",
    "combined_20_23 = pd.concat([combined_20_23, mh2022], axis=0)\n",
    "combined_20_23 = pd.concat([combined_20_23, mh2023], axis=0)\n",
    "combined_20_23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2: Income Data by State (2020-2022) [Confounding Variable #1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Group</th>\n",
       "      <th>Total</th>\n",
       "      <th>Less than $10,000</th>\n",
       "      <th>$10,000 to $14,999</th>\n",
       "      <th>$15,000 to $24,999</th>\n",
       "      <th>$25,000 to $34,999</th>\n",
       "      <th>$35,000 to $49,999</th>\n",
       "      <th>$50,000 to $74,999</th>\n",
       "      <th>$75,000 to $99,999</th>\n",
       "      <th>$100,000 to $149,999</th>\n",
       "      <th>$150,000 to $199,999</th>\n",
       "      <th>$200,000 or more</th>\n",
       "      <th>Median income (dollars)</th>\n",
       "      <th>Mean income (dollars)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>Households</td>\n",
       "      <td>1888504</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.044</td>\n",
       "      <td>52035</td>\n",
       "      <td>71964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>Families</td>\n",
       "      <td>1234552</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.061</td>\n",
       "      <td>66772</td>\n",
       "      <td>86610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>Married-couple families</td>\n",
       "      <td>893948</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.081</td>\n",
       "      <td>82058</td>\n",
       "      <td>102291.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>Nonfamily households</td>\n",
       "      <td>653952</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.012</td>\n",
       "      <td>28529</td>\n",
       "      <td>42194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2020</td>\n",
       "      <td>Households</td>\n",
       "      <td>255173</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.088</td>\n",
       "      <td>77790</td>\n",
       "      <td>98811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2022</td>\n",
       "      <td>Nonfamily households</td>\n",
       "      <td>980016</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.024</td>\n",
       "      <td>42812</td>\n",
       "      <td>57892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022</td>\n",
       "      <td>Households</td>\n",
       "      <td>243321</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.066</td>\n",
       "      <td>70042</td>\n",
       "      <td>90018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022</td>\n",
       "      <td>Families</td>\n",
       "      <td>153365</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.082</td>\n",
       "      <td>86552</td>\n",
       "      <td>106006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022</td>\n",
       "      <td>Married-couple families</td>\n",
       "      <td>119329</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.099</td>\n",
       "      <td>98789</td>\n",
       "      <td>117273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022</td>\n",
       "      <td>Nonfamily households</td>\n",
       "      <td>89956</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.033</td>\n",
       "      <td>40019</td>\n",
       "      <td>57301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         State  Year                    Group    Total  Less than $10,000  \\\n",
       "1      Alabama  2020               Households  1888504              0.081   \n",
       "3      Alabama  2020                 Families  1234552              0.046   \n",
       "5      Alabama  2020  Married-couple families   893948              0.015   \n",
       "7      Alabama  2020     Nonfamily households   653952              0.156   \n",
       "9       Alaska  2020               Households   255173              0.038   \n",
       "..         ...   ...                      ...      ...                ...   \n",
       "399  Wisconsin  2022     Nonfamily households   980016              0.084   \n",
       "401    Wyoming  2022               Households   243321              0.052   \n",
       "403    Wyoming  2022                 Families   153365              0.032   \n",
       "405    Wyoming  2022  Married-couple families   119329              0.018   \n",
       "407    Wyoming  2022     Nonfamily households    89956              0.096   \n",
       "\n",
       "     $10,000 to $14,999  $15,000 to $24,999  $25,000 to $34,999  \\\n",
       "1                 0.056               0.109               0.105   \n",
       "3                 0.028               0.077               0.090   \n",
       "5                 0.013               0.045               0.067   \n",
       "7                 0.111               0.178               0.135   \n",
       "9                 0.029               0.062               0.067   \n",
       "..                  ...                 ...                 ...   \n",
       "399               0.068               0.129               0.121   \n",
       "401               0.034               0.075               0.082   \n",
       "403               0.014               0.047               0.056   \n",
       "405               0.007               0.031               0.040   \n",
       "407               0.069               0.133               0.127   \n",
       "\n",
       "     $35,000 to $49,999  $50,000 to $74,999  $75,000 to $99,999  \\\n",
       "1                 0.132               0.175               0.118   \n",
       "3                 0.126               0.190               0.143   \n",
       "5                 0.113               0.196               0.168   \n",
       "7                 0.141               0.142               0.065   \n",
       "9                 0.101               0.183               0.142   \n",
       "..                  ...                 ...                 ...   \n",
       "399               0.167               0.193               0.104   \n",
       "401               0.113               0.177               0.138   \n",
       "403               0.098               0.181               0.156   \n",
       "405               0.075               0.177               0.160   \n",
       "407               0.159               0.175               0.104   \n",
       "\n",
       "     $100,000 to $149,999  $150,000 to $199,999  $200,000 or more  \\\n",
       "1                   0.131                 0.049             0.044   \n",
       "3                   0.172                 0.067             0.061   \n",
       "5                   0.216                 0.087             0.081   \n",
       "7                   0.048                 0.012             0.012   \n",
       "9                   0.193                 0.096             0.088   \n",
       "..                    ...                   ...               ...   \n",
       "399                 0.088                 0.021             0.024   \n",
       "401                 0.187                 0.076             0.066   \n",
       "403                 0.233                 0.103             0.082   \n",
       "405                 0.263                 0.130             0.099   \n",
       "407                 0.082                 0.022             0.033   \n",
       "\n",
       "     Median income (dollars)  Mean income (dollars)  \n",
       "1                      52035                71964.0  \n",
       "3                      66772                86610.0  \n",
       "5                      82058               102291.0  \n",
       "7                      28529                42194.0  \n",
       "9                      77790                98811.0  \n",
       "..                       ...                    ...  \n",
       "399                    42812                57892.0  \n",
       "401                    70042                90018.0  \n",
       "403                    86552               106006.0  \n",
       "405                    98789               117273.0  \n",
       "407                    40019                57301.0  \n",
       "\n",
       "[612 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "state_names = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \n",
    "    \"California\", \"Colorado\", \"Connecticut\", \n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \n",
    "    \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \n",
    "    \"Maryland\", \"Massachusetts\", \"Michigan\", \n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \n",
    "    \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n",
    "    \"New Jersey\", \"New Mexico\", \"New York\",\n",
    "    \"North Carolina\", \"North Dakota\", \"Ohio\",\n",
    "    \"Oklahoma\", \"Oregon\", \"Pennsylvania\",\n",
    "    \"Rhode Island\", \"South Carolina\",\n",
    "    \"South Dakota\", \"Tennessee\", \"Texas\",\n",
    "    \"Utah\", \"Vermont\", \"Virginia\", \"Washington\",\n",
    "    \"West Virginia\", \"Wisconsin\", \"Wyoming\"]\n",
    "    \n",
    "def clean_row_name(string):\n",
    "    string = string.strip()\n",
    "    string = string.replace('!!', ' ')\n",
    "    return string\n",
    "\n",
    "def clean_column_names(columns):\n",
    "    output = []\n",
    "    for c in columns:\n",
    "        c = c.strip()\n",
    "        c = c.replace('\\n', ' ')\n",
    "        c = c.replace('\\t', ' ')\n",
    "        output.append(c)\n",
    "    return output\n",
    "\n",
    "def label_state(string):\n",
    "    \"\"\" Covers cases where state has two words or one\"\"\"\n",
    "    string = string.split()\n",
    "    opt1 = string[0] + ' ' + string[1]\n",
    "    opt2 = string[0]\n",
    "    if opt1 in state_names:\n",
    "        return opt1\n",
    "    if opt2 in state_names:\n",
    "        return opt2\n",
    "    else:\n",
    "        return 'Washington D.C.'\n",
    "\n",
    "def find_moe(string):\n",
    "    \"\"\" Identify which rows have margin of error information to drop \"\"\"\n",
    "    if (\"Margin of Error\" in string):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def to_integer(string):\n",
    "    \"\"\" Converts elements of columns to integer values \"\"\"\n",
    "    string = string.strip()\n",
    "    string = string.replace(',', '')\n",
    "    string = string.strip()\n",
    "    try:\n",
    "        return int(string)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def to_float(string):\n",
    "    \"\"\" Converts elements of columns to float values \"\"\"\n",
    "    string = string.strip()\n",
    "    string = string.replace(',', '')\n",
    "    string = string.replace('%', '')\n",
    "    string = float(string)\n",
    "    return string / 100\n",
    "\n",
    "def extract_group(string):\n",
    "    \"\"\" Extracts label on household type \"\"\"\n",
    "    if 'Households' in string:\n",
    "        return 'Households'\n",
    "    elif 'Families' in string:\n",
    "        return 'Families'\n",
    "    elif 'Married' in string:\n",
    "        return 'Married-couple families'\n",
    "    elif 'Nonfamily households':\n",
    "        return 'Nonfamily households'\n",
    "    else:\n",
    "        return 'error'\n",
    "\n",
    "def poverty_wrangler(file, year):\n",
    "    # Read in data for particular year\n",
    "    income = pd.read_csv(file)\n",
    "    income = income.transpose()\n",
    "\n",
    "    # Make first column entries readable\n",
    "    income = income.reset_index()\n",
    "    income['index'] = income['index'].apply(clean_row_name)\n",
    "    income.loc[0, 'index'] = 'Group'\n",
    "\n",
    "    # Create DataFrame header\n",
    "    income = income.set_axis(clean_column_names(income.iloc[0]), axis=1).iloc[1:]\n",
    "\n",
    "    # Drop columns with many missing values\n",
    "    income = income.get(income.columns[:-4])\n",
    "\n",
    "    # Add column to label state name and year\n",
    "    income = income.assign(State = income['Group'].apply(label_state))\n",
    "    income = income.assign(Year = year)\n",
    "    income = income[['State', 'Year'] + list(income.columns.values)[:-2]]\n",
    "\n",
    "    # Drop rows describing margin of error\n",
    "    income = income[~income['Group'].apply(find_moe)]\n",
    "\n",
    "    # Convert integer valued rows to integers\n",
    "    income['Total'] = income['Total'].apply(to_integer)\n",
    "    income['Median income (dollars)'] = income['Median income (dollars)'].apply(to_integer)\n",
    "    income['Mean income (dollars)'] = income['Mean income (dollars)'].apply(to_integer)\n",
    "\n",
    "    # Convert float valued (percent) rows to proportions\n",
    "    income['Less than $10,000'] = income['Less than $10,000'].apply(to_float)\n",
    "    income['$10,000 to $14,999'] = income['$10,000 to $14,999'].apply(to_float)\n",
    "    income['$15,000 to $24,999'] = income['$15,000 to $24,999'].apply(to_float)\n",
    "    income['$25,000 to $34,999'] = income['$25,000 to $34,999'].apply(to_float)\n",
    "    income['$35,000 to $49,999'] = income['$35,000 to $49,999'].apply(to_float)\n",
    "    income['$50,000 to $74,999'] = income['$50,000 to $74,999'].apply(to_float)\n",
    "    income['$75,000 to $99,999'] = income['$75,000 to $99,999'].apply(to_float)\n",
    "    income['$100,000 to $149,999'] = income['$100,000 to $149,999'].apply(to_float)\n",
    "    income['$150,000 to $199,999'] = income['$150,000 to $199,999'].apply(to_float)\n",
    "    income['$200,000 or more'] = income['$200,000 or more'].apply(to_float)\n",
    "\n",
    "    # Rework columns and observations\n",
    "    income = income.assign(Group = income['Group'].apply(extract_group))\n",
    "\n",
    "    return income\n",
    "\n",
    "income22 = poverty_wrangler('data/poverty_state_2022.csv', 2022)\n",
    "income21 = poverty_wrangler('data/poverty_state_2021.csv', 2021)\n",
    "income20 = poverty_wrangler('data/poverty_state_2020.csv', 2020)\n",
    "\n",
    "combined_income = pd.concat([income20, income21], axis=0)\n",
    "combined_income = pd.concat([combined_income, income22], axis=0)\n",
    "combined_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?\n",
    "\n",
    "\n",
    "There are several ethical issues to consider when observing our data science process. Firstly, our question attempts to generalize the effect of legislation that targets only a subset of a population to the general state population. This requires careful consideration of confounding variables to assure that we are, indeed, getting as close as possible to answering our question for the general population as related to anti-LGBTQ rights laws. So far, we have looked at data on mental health accessibility and poverty, which may be the leading mental health confounders for our research question. We may need to consider more.\n",
    "\n",
    "Additionally, our question is concerned with rather sensitive subject matter. While no personal data is being used (mostly only summary statistics per state and legislation information, which is public), we must still be mindful of the implications of our findings. We do not want to imply that anti-LGBTQ laws are inconsequential should we not find a significant effect on the general population by state; there are people, especially those part of the LGBTQ community, who are being affected personally by these laws. We must also be careful in our discussion when suggesting future steps, should the effect be significant and convincingly strong. Since our question is unique to anti-LGBTQ laws, we should not make generalizing assumptions about the overall state of human rights in each state. If we do discuss human rights as whole, we will be clear that we are merely extrapolating from our current findings.\n",
    "\n",
    "The data itself are publicly available and free to download for use. No personal/individual information is involved, and state/census/legislation data is freely available to the public, so data privacy is not a major concern for our research. However, our data may exclude certain populations. Dataset #1 (Mental Health Risk Screening) is generally accessible to everyone, since the mental health screens used are taken online by individuals wishing to quickly analyze their current mental health. The accuracy of these screens is one consideration, since a single person may not accurately reflect their mental health situation. It is also important to consider that many people who struggle with mental health won't take these screening tests, especially the one provided by MHA. A large subset of the population is likely left out, even after considering 5 million screens. However, because the data are provided in \"per 100K of the state population\" format, we can treat proportions as comparisons between states as opposed to exact measures for a particular state. This will help mitigate the issue of many individuals excluded. We may not have this issue with legislation and mental health resource data, since these data do not rely on human sampling and have direct access to statistics. Census poverty may not be perfectly represented, since it relies on only estimating poverty rate. However, as with mental health, we can use proportions to our advantage and use it is as a comparative metric as opposed to an exact representation of poverty in a state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. All team members should be present at the meeting, and any time conflicts should be made clear ahead of time so meeting can occur at a time that suits everyone\n",
    "2. The work needed to be done should be divided up into tasks and assigned to each group member evenly. All members should have some sort of contribution to writing the code, the text that explains different parts of the project, etc.\n",
    "3. If anyone is stuck on a task, feel free to reach out to the groupchat for help, and we will try our best to collaborate on the issue at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/3  | 12 PM | NA  | Delegated roles for previous project review; Completed project review | \n",
    "| 2/8  | 6 PM  | Find potential topics and datasets for project  | Narrowed down the topic and found preliminary data; Delegated roles in Project Proposal | \n",
    "| 2/17  |  12 PM | Prepare sources for data on topic  | Kept searching for data (asynchronous) | \n",
    "| 2/22  |  6 PM | Find more sources | Discussed changing the research question; Discussed confounders for new research question; Assigned roles for Checkpoint #1  | \n",
    "| 3/2  | 12 PM | Perform individual EDA on collected data | Discuss findings from EDA; Finalize final project roles | \n",
    "| 3/9  | 12 PM | Prepare Checkpoint #2 | Discuss/Finish Checkpoint #2; Revisit analysis strategies for final project | \n",
    "| 3/14 | 6 PM | Work on assigned final project role | Discuss current work with team; Continue analyis; Check for quality, accuracy, and equal work distribution | \n",
    "| 3/17 | 12 PM | Fix any issues found from previous meeting | Finish analysis; Start on results and conclusion/discussion section | \n",
    "| 3/20 | < 11:59 PM | Final check of project by each group member | Submit project and group survey after all members approve | \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
