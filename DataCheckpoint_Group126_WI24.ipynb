{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Ant Man\n",
    "- Hulk\n",
    "- Iron Man\n",
    "- Thor\n",
    "- Wasp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Include a specific, clear data science question.\n",
    "-  Make sure what you're measuring (variables) to answer the question is clear\n",
    "\n",
    "What is your research question? Include the specific question you're setting out to answer. This question should be specific, answerable with data, and clear. A general question with specific subquestions is permitted. (1-2 sentences)\n",
    "\n",
    "Since 2020, how does the number of anti-LGBT laws passed per year and their severity (e.g. number of affected individuals) impact the mental health (e.g. risk of depression, suicide, PTSD) of the general population within each U.S. state? Additionally, is there a differential effect on mental health outcomes across age groups and other demographics, such as socioeconomic status, race, and gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include a general introduction to your topic\n",
    "- Include explanation of what work has been done previously\n",
    "- Include citations or links to previous work\n",
    "\n",
    "This section will present the background and context of your topic and question in a few paragraphs. Include a general introduction to your topic and then describe what information you currently know about the topic after doing your initial research. Include references to other projects who have asked similar questions or approached similar problems. Explain what others have learned in their projects.\n",
    "\n",
    "Find some relevant prior work, and reference those sources, summarizing what each did and what they learned. Even if you think you have a totally novel question, find the most similar prior work that you can and discuss how it relates to your project.\n",
    "\n",
    "References can be research publications, but they need not be. Blogs, GitHub repositories, company websites, etc., are all viable references if they are relevant to your project. It must be clear which information comes from which references. (2-3 paragraphs, including at least 2 references)\n",
    "\n",
    " **Use inline citation through HTML footnotes to specify which references support which statements** \n",
    "\n",
    "For example: After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Use a minimum of 2 or 3 citations, but we prefer more.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) You need enough to fully explain and back up important facts. \n",
    "\n",
    "Note that if you click a footnote number in the paragraph above it will transport you to the proper entry in the footnotes list below.  And if you click the ^ in the footnote entry, it will return you to the place in the main text where the footnote is made.\n",
    "\n",
    "To understand the HTML here, `<a name=\"#...\"> </a>` is a tag that allows you produce a named reference for a given location.  Markdown has the construciton `[text with hyperlink](#named reference)` that will produce a clickable link that transports you the named reference.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Lorenz, T. (9 Dec 2021) Birds Arenâ€™t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include your team's hypothesis\n",
    "- Ensure that this hypothesis is clear to readers\n",
    "- Explain why you think this will be the outcome (what was your thinking?)\n",
    "\n",
    "What is your main hypothesis/predictions about what the answer to your question is? Briefly explain your thinking. (2-3 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- etc\n",
    "\n",
    "Now write 2 - 5 sentences describing each dataset here. Include a short description of the important variables in the dataset; what the metrics and datatypes are, what concepts they may be proxies for. Include information about how you would need to wrangle/clean/preprocess the dataset\n",
    "\n",
    "Erik wrote a function to clean the dataset from being a text file into being a csv. He had to copy and paste and a lot of times, reformat the information because the formatting fell apart a bit in some places. This will allow us to use the function to make tables which have a column specifying which part of the original document the data came from, which will allow us to distinguish different types of laws that have been passed.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1: Mental Health Data from 2020-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Group Type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Psychotic Episodes</th>\n",
       "      <th>Trauma Survivors</th>\n",
       "      <th>Suicidal Ideation</th>\n",
       "      <th>PTSD</th>\n",
       "      <th>Severe Depression</th>\n",
       "      <th>Total Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>29.088011</td>\n",
       "      <td>53.235426</td>\n",
       "      <td>45.338408</td>\n",
       "      <td>13.730494</td>\n",
       "      <td>41.945468</td>\n",
       "      <td>5039877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>49.544613</td>\n",
       "      <td>98.133820</td>\n",
       "      <td>83.120301</td>\n",
       "      <td>25.386496</td>\n",
       "      <td>70.836512</td>\n",
       "      <td>732673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>25.411211</td>\n",
       "      <td>54.244483</td>\n",
       "      <td>47.331644</td>\n",
       "      <td>13.482097</td>\n",
       "      <td>43.895840</td>\n",
       "      <td>7276316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>26.768975</td>\n",
       "      <td>58.197734</td>\n",
       "      <td>40.087366</td>\n",
       "      <td>18.275609</td>\n",
       "      <td>39.029826</td>\n",
       "      <td>3025891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>18.698789</td>\n",
       "      <td>42.030860</td>\n",
       "      <td>41.340200</td>\n",
       "      <td>10.408321</td>\n",
       "      <td>37.298183</td>\n",
       "      <td>39237836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>18.298822</td>\n",
       "      <td>78.941741</td>\n",
       "      <td>41.284630</td>\n",
       "      <td>16.133826</td>\n",
       "      <td>37.507403</td>\n",
       "      <td>8683619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>21.783286</td>\n",
       "      <td>105.602697</td>\n",
       "      <td>45.017934</td>\n",
       "      <td>18.636526</td>\n",
       "      <td>39.713396</td>\n",
       "      <td>7785786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>26.983544</td>\n",
       "      <td>97.399890</td>\n",
       "      <td>40.954147</td>\n",
       "      <td>23.716226</td>\n",
       "      <td>40.672482</td>\n",
       "      <td>1775156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>19.668941</td>\n",
       "      <td>86.431333</td>\n",
       "      <td>40.016706</td>\n",
       "      <td>15.680847</td>\n",
       "      <td>35.264934</td>\n",
       "      <td>5892539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2023</td>\n",
       "      <td>20.124497</td>\n",
       "      <td>102.686534</td>\n",
       "      <td>43.345070</td>\n",
       "      <td>20.640509</td>\n",
       "      <td>42.485049</td>\n",
       "      <td>581381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            State Group Type  Year  Psychotic Episodes  Trauma Survivors  \\\n",
       "0         Alabama   All Ages  2020           29.088011         53.235426   \n",
       "1          Alaska   All Ages  2020           49.544613         98.133820   \n",
       "2         Arizona   All Ages  2020           25.411211         54.244483   \n",
       "3        Arkansas   All Ages  2020           26.768975         58.197734   \n",
       "4      California   All Ages  2020           18.698789         42.030860   \n",
       "..            ...        ...   ...                 ...               ...   \n",
       "46       Virginia   All Ages  2023           18.298822         78.941741   \n",
       "47     Washington   All Ages  2023           21.783286        105.602697   \n",
       "48  West Virginia   All Ages  2023           26.983544         97.399890   \n",
       "49      Wisconsin   All Ages  2023           19.668941         86.431333   \n",
       "50        Wyoming   All Ages  2023           20.124497        102.686534   \n",
       "\n",
       "    Suicidal Ideation       PTSD  Severe Depression  Total Population  \n",
       "0           45.338408  13.730494          41.945468           5039877  \n",
       "1           83.120301  25.386496          70.836512            732673  \n",
       "2           47.331644  13.482097          43.895840           7276316  \n",
       "3           40.087366  18.275609          39.029826           3025891  \n",
       "4           41.340200  10.408321          37.298183          39237836  \n",
       "..                ...        ...                ...               ...  \n",
       "46          41.284630  16.133826          37.507403           8683619  \n",
       "47          45.017934  18.636526          39.713396           7785786  \n",
       "48          40.954147  23.716226          40.672482           1775156  \n",
       "49          40.016706  15.680847          35.264934           5892539  \n",
       "50          43.345070  20.640509          42.485049            581381  \n",
       "\n",
       "[204 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "renamer = {\n",
    "    'Age1': 'Group Type',\n",
    "    'Year1': 'Year',\n",
    "    'Number of People At Possible Risk for Psychotic-Like Episodes': 'Psychotic Episodes',\n",
    "    'Number of People Identifying as Trauma Survivors': 'Trauma Survivors',\n",
    "    'Number of People Reporting Frequent Suicidal Ideation': 'Suicidal Ideation',\n",
    "    'Number of People Scoring Positive for PTSD': 'PTSD',\n",
    "    'Number of People Scoring with Severe Depression': 'Severe Depression'\n",
    "}\n",
    "\n",
    "to_keep = ['State', 'Group Type', 'Year',\n",
    "           'Psychotic Episodes', 'Trauma Survivors',\n",
    "           'Suicidal Ideation', 'PTSD',\n",
    "           'Severe Depression', 'Total Population']\n",
    "\n",
    "mh2020 = pd.read_csv('data/full_mh_2020.csv')\n",
    "mh2020 = mh2020.rename(renamer, axis=1)\n",
    "mh2020 = mh2020[(to_keep)]\n",
    "\n",
    "mh2021 = pd.read_csv('data/full_mh_2021.csv')\n",
    "mh2021 = mh2021.rename(renamer, axis=1)\n",
    "mh2021 = mh2021[(to_keep)]\n",
    "\n",
    "mh2022 = pd.read_csv('data/full_mh_2022.csv')\n",
    "mh2022 = mh2022.rename(renamer, axis=1)\n",
    "mh2022 = mh2022[(to_keep)]\n",
    "\n",
    "mh2023 = pd.read_csv('data/full_mh_2023.csv')\n",
    "mh2023 = mh2023.rename(renamer, axis=1)\n",
    "mh2023 = mh2023[(to_keep)]\n",
    "\n",
    "combined_20_23 = pd.concat([mh2020, mh2021], axis=0)\n",
    "combined_20_23 = pd.concat([combined_20_23, mh2022], axis=0)\n",
    "combined_20_23 = pd.concat([combined_20_23, mh2023], axis=0)\n",
    "combined_20_23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2: Income Data by State (2022) [Confounding Variable #1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>2022 State Info</th>\n",
       "      <th>Total</th>\n",
       "      <th>Less than $10,000</th>\n",
       "      <th>$10,000 to $14,999</th>\n",
       "      <th>$15,000 to $24,999</th>\n",
       "      <th>$25,000 to $34,999</th>\n",
       "      <th>$35,000 to $49,999</th>\n",
       "      <th>$50,000 to $74,999</th>\n",
       "      <th>$75,000 to $99,999</th>\n",
       "      <th>$100,000 to $149,999</th>\n",
       "      <th>$150,000 to $199,999</th>\n",
       "      <th>$200,000 or more</th>\n",
       "      <th>Median income (dollars)</th>\n",
       "      <th>Mean income (dollars)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama Households Estimate</td>\n",
       "      <td>2016448</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.067</td>\n",
       "      <td>59674</td>\n",
       "      <td>82956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama Families Estimate</td>\n",
       "      <td>1308988</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.092</td>\n",
       "      <td>77668</td>\n",
       "      <td>100785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama Married-couple families Estimate</td>\n",
       "      <td>941596</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.121</td>\n",
       "      <td>94370</td>\n",
       "      <td>118799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama Nonfamily households Estimate</td>\n",
       "      <td>707460</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.016</td>\n",
       "      <td>32330</td>\n",
       "      <td>47145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>Alaska Households Estimate</td>\n",
       "      <td>274574</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.114</td>\n",
       "      <td>88121</td>\n",
       "      <td>109524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>West Virginia Nonfamily households Estimate</td>\n",
       "      <td>273277</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.019</td>\n",
       "      <td>31082</td>\n",
       "      <td>48384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wisconsin Households Estimate</td>\n",
       "      <td>2491121</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.076</td>\n",
       "      <td>70996</td>\n",
       "      <td>94085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wisconsin Families Estimate</td>\n",
       "      <td>1511105</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.107</td>\n",
       "      <td>91700</td>\n",
       "      <td>114906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wisconsin Married-couple families Estimate</td>\n",
       "      <td>1171977</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.131</td>\n",
       "      <td>105109</td>\n",
       "      <td>129517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wisconsin Nonfamily households Estimate</td>\n",
       "      <td>980016</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.024</td>\n",
       "      <td>42812</td>\n",
       "      <td>57892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             State                              2022 State Info    Total  \\\n",
       "1          Alabama                  Alabama Households Estimate  2016448   \n",
       "3          Alabama                    Alabama Families Estimate  1308988   \n",
       "5          Alabama     Alabama Married-couple families Estimate   941596   \n",
       "7          Alabama        Alabama Nonfamily households Estimate   707460   \n",
       "9           Alaska                   Alaska Households Estimate   274574   \n",
       "..             ...                                          ...      ...   \n",
       "391  West Virginia  West Virginia Nonfamily households Estimate   273277   \n",
       "393      Wisconsin                Wisconsin Households Estimate  2491121   \n",
       "395      Wisconsin                  Wisconsin Families Estimate  1511105   \n",
       "397      Wisconsin   Wisconsin Married-couple families Estimate  1171977   \n",
       "399      Wisconsin      Wisconsin Nonfamily households Estimate   980016   \n",
       "\n",
       "     Less than $10,000  $10,000 to $14,999  $15,000 to $24,999  \\\n",
       "1                0.076               0.052               0.093   \n",
       "3                0.044               0.030               0.060   \n",
       "5                0.017               0.011               0.034   \n",
       "7                0.143               0.098               0.159   \n",
       "9                0.044               0.025               0.054   \n",
       "..                 ...                 ...                 ...   \n",
       "391              0.125               0.121               0.171   \n",
       "393              0.046               0.035               0.070   \n",
       "395              0.026               0.014               0.036   \n",
       "397              0.013               0.007               0.020   \n",
       "399              0.084               0.068               0.129   \n",
       "\n",
       "     $25,000 to $34,999  $35,000 to $49,999  $50,000 to $74,999  \\\n",
       "1                 0.086               0.120               0.167   \n",
       "3                 0.069               0.107               0.173   \n",
       "5                 0.049               0.084               0.172   \n",
       "7                 0.125               0.145               0.157   \n",
       "9                 0.053               0.091               0.158   \n",
       "..                  ...                 ...                 ...   \n",
       "391               0.140               0.137               0.143   \n",
       "393               0.074               0.120               0.181   \n",
       "395               0.048               0.093               0.176   \n",
       "397               0.030               0.071               0.161   \n",
       "399               0.121               0.167               0.193   \n",
       "\n",
       "     $75,000 to $99,999  $100,000 to $149,999  $150,000 to $199,999  \\\n",
       "1                 0.126                 0.149                 0.064   \n",
       "3                 0.144                 0.194                 0.087   \n",
       "5                 0.165                 0.236                 0.112   \n",
       "7                 0.081                 0.057                 0.019   \n",
       "9                 0.132                 0.218                 0.111   \n",
       "..                  ...                   ...                   ...   \n",
       "391               0.073                 0.059                 0.013   \n",
       "393               0.137                 0.181                 0.080   \n",
       "395               0.156                 0.232                 0.113   \n",
       "397               0.163                 0.266                 0.138   \n",
       "399               0.104                 0.088                 0.021   \n",
       "\n",
       "     $200,000 or more  Median income (dollars)  Mean income (dollars)  \n",
       "1               0.067                    59674                  82956  \n",
       "3               0.092                    77668                 100785  \n",
       "5               0.121                    94370                 118799  \n",
       "7               0.016                    32330                  47145  \n",
       "9               0.114                    88121                 109524  \n",
       "..                ...                      ...                    ...  \n",
       "391             0.019                    31082                  48384  \n",
       "393             0.076                    70996                  94085  \n",
       "395             0.107                    91700                 114906  \n",
       "397             0.131                   105109                 129517  \n",
       "399             0.024                    42812                  57892  \n",
       "\n",
       "[200 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "state_names = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \n",
    "    \"California\", \"Colorado\", \"Connecticut\", \n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \n",
    "    \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \n",
    "    \"Maryland\", \"Massachusetts\", \"Michigan\", \n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \n",
    "    \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n",
    "    \"New Jersey\", \"New Mexico\", \"New York\",\n",
    "    \"North Carolina\", \"North Dakota\", \"Ohio\",\n",
    "    \"Oklahoma\", \"Oregon\", \"Pennsylvania\",\n",
    "    \"Rhode Island\", \"South Carolina\",\n",
    "    \"South Dakota\", \"Tennessee\", \"Texas\",\n",
    "    \"Utah\", \"Vermont\", \"Virginia\", \"Washington\",\n",
    "    \"West Virginia\", \"Wisconsin\", \"Wyoming\"]\n",
    "    \n",
    "def clean_row_name(string):\n",
    "    string = string.strip()\n",
    "    string = string.replace('!!', ' ')\n",
    "    return string\n",
    "\n",
    "def clean_column_names(columns):\n",
    "    output = []\n",
    "    for c in columns:\n",
    "        c = c.strip()\n",
    "        c = c.replace('\\n', ' ')\n",
    "        c = c.replace('\\t', ' ')\n",
    "        output.append(c)\n",
    "    return output\n",
    "\n",
    "def label_state(string):\n",
    "    \"\"\" Covers cases where state has two words or one\"\"\"\n",
    "    string = string.split()\n",
    "    opt1 = string[0] + ' ' + string[1]\n",
    "    opt2 = string[0]\n",
    "    if opt1 in state_names:\n",
    "        return opt1\n",
    "    if opt2 in state_names:\n",
    "        return opt2\n",
    "\n",
    "def find_moe(string):\n",
    "    \"\"\" Identify which rows have margin of error information to drop \"\"\"\n",
    "    if (\"Margin of Error\" in string):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def to_integer(string):\n",
    "    \"\"\" Converts elements of columns to integer values \"\"\"\n",
    "    string = string.strip()\n",
    "    string = string.replace(',', '')\n",
    "    string = string.strip()\n",
    "    return int(string)\n",
    "\n",
    "def to_float(string):\n",
    "    \"\"\" Converts elements of columns to float values \"\"\"\n",
    "    string = string.strip()\n",
    "    string = string.replace(',', '')\n",
    "    string = string.replace('%', '')\n",
    "    string = float(string)\n",
    "    return string / 100\n",
    "\n",
    "# Read in data for particular year\n",
    "income = pd.read_csv(\"data/povery_state_2022.csv\")\n",
    "income = income.transpose()\n",
    "\n",
    "# Make first column entries readable\n",
    "income = income.reset_index()\n",
    "income['index'] = income['index'].apply(clean_row_name)\n",
    "income.loc[0, 'index'] = '2022 State Info'\n",
    "\n",
    "# Create DataFrame header\n",
    "income = income.set_axis(clean_column_names(income.iloc[0]), axis=1).iloc[1:]\n",
    "\n",
    "# Drop columns with many missing values\n",
    "income = income.get(income.columns[:-4])\n",
    "\n",
    "# Add column to label with state name\n",
    "income = income.assign(State = income['2022 State Info'].apply(label_state))\n",
    "income = income[['State'] + list(income.columns.values)[:-1]]\n",
    "\n",
    "# Drop rows describing margin of error\n",
    "income = income[~income['2022 State Info'].apply(find_moe)]\n",
    "\n",
    "# Convert integer valued rows to integers\n",
    "income['Total'] = income['Total'].apply(to_integer)\n",
    "income['Median income (dollars)'] = income['Median income (dollars)'].apply(to_integer)\n",
    "income['Mean income (dollars)'] = income['Mean income (dollars)'].apply(to_integer)\n",
    "\n",
    "# Convert float valued (percent) rows to proportions\n",
    "income['Less than $10,000'] = income['Less than $10,000'].apply(to_float)\n",
    "income['$10,000 to $14,999'] = income['$10,000 to $14,999'].apply(to_float)\n",
    "income['$15,000 to $24,999'] = income['$15,000 to $24,999'].apply(to_float)\n",
    "income['$25,000 to $34,999'] = income['$25,000 to $34,999'].apply(to_float)\n",
    "income['$35,000 to $49,999'] = income['$35,000 to $49,999'].apply(to_float)\n",
    "income['$50,000 to $74,999'] = income['$50,000 to $74,999'].apply(to_float)\n",
    "income['$75,000 to $99,999'] = income['$75,000 to $99,999'].apply(to_float)\n",
    "income['$100,000 to $149,999'] = income['$100,000 to $149,999'].apply(to_float)\n",
    "income['$150,000 to $199,999'] = income['$150,000 to $199,999'].apply(to_float)\n",
    "income['$200,000 or more'] = income['$200,000 or more'].apply(to_float)\n",
    "\n",
    "income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your groupâ€™s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each memberâ€™s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your teamâ€™s expectations below, and have every intention to fulfill them. These expectations are for your teamâ€™s use and benefit â€” they wonâ€™t be graded for their details.\n",
    "\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what youâ€™re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data (Ant Man); EDA (Hulk) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin Analysis (Iron Man; Thor) | Discuss/edit Analysis; Complete project check-in |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
