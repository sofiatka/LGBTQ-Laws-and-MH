{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be2d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255d64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \n",
    "    \"California\", \"Colorado\", \"Connecticut\", \n",
    "    \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \n",
    "    \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \n",
    "    \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \n",
    "    \"Maryland\", \"Massachusetts\", \"Michigan\", \n",
    "    \"Minnesota\", \"Mississippi\", \"Missouri\", \n",
    "    \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\",\n",
    "    \"New Jersey\", \"New Mexico\", \"New York\",\n",
    "    \"North Carolina\", \"North Dakota\", \"Ohio\",\n",
    "    \"Oklahoma\", \"Oregon\", \"Pennsylvania\",\n",
    "    \"Rhode Island\", \"South Carolina\",\n",
    "    \"South Dakota\", \"Tennessee\", \"Texas\",\n",
    "    \"Utah\", \"Vermont\", \"Virginia\", \"Washington\",\n",
    "    \"West Virginia\", \"Wisconsin\", \"Wyoming\"]\n",
    "\n",
    "state_mapping = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "    'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri',\n",
    "    'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "def keep_state(string):\n",
    "    if string in state_mapping:\n",
    "        string = state_mapping[string]\n",
    "    return string in state_names\n",
    "\n",
    "def clear_nan(inp):\n",
    "    if np.isnan(inp):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67925516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Group</th>\n",
       "      <th>Year</th>\n",
       "      <th>Psychotic Episodes</th>\n",
       "      <th>Trauma Survivors</th>\n",
       "      <th>Suicidal Ideation</th>\n",
       "      <th>PTSD</th>\n",
       "      <th>Severe Depression</th>\n",
       "      <th>Total Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>29.088</td>\n",
       "      <td>53.235</td>\n",
       "      <td>45.338</td>\n",
       "      <td>13.730</td>\n",
       "      <td>41.945</td>\n",
       "      <td>5039877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>49.545</td>\n",
       "      <td>98.134</td>\n",
       "      <td>83.120</td>\n",
       "      <td>25.386</td>\n",
       "      <td>70.837</td>\n",
       "      <td>732673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>25.411</td>\n",
       "      <td>54.244</td>\n",
       "      <td>47.332</td>\n",
       "      <td>13.482</td>\n",
       "      <td>43.896</td>\n",
       "      <td>7276316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>26.769</td>\n",
       "      <td>58.198</td>\n",
       "      <td>40.087</td>\n",
       "      <td>18.276</td>\n",
       "      <td>39.030</td>\n",
       "      <td>3025891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>18.699</td>\n",
       "      <td>42.031</td>\n",
       "      <td>41.340</td>\n",
       "      <td>10.408</td>\n",
       "      <td>37.298</td>\n",
       "      <td>39237836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>31.657</td>\n",
       "      <td>109.271</td>\n",
       "      <td>99.523</td>\n",
       "      <td>20.247</td>\n",
       "      <td>78.847</td>\n",
       "      <td>1866910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>39.658</td>\n",
       "      <td>137.073</td>\n",
       "      <td>115.573</td>\n",
       "      <td>23.260</td>\n",
       "      <td>89.944</td>\n",
       "      <td>1646573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>42.339</td>\n",
       "      <td>128.438</td>\n",
       "      <td>90.645</td>\n",
       "      <td>25.006</td>\n",
       "      <td>77.858</td>\n",
       "      <td>351922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>33.397</td>\n",
       "      <td>128.610</td>\n",
       "      <td>98.344</td>\n",
       "      <td>21.355</td>\n",
       "      <td>79.799</td>\n",
       "      <td>1245629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>32.279</td>\n",
       "      <td>142.952</td>\n",
       "      <td>103.755</td>\n",
       "      <td>26.899</td>\n",
       "      <td>92.995</td>\n",
       "      <td>130114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            State             Group  Year  Psychotic Episodes  \\\n",
       "0         Alabama          All Ages  2020              29.088   \n",
       "1          Alaska          All Ages  2020              49.545   \n",
       "2         Arizona          All Ages  2020              25.411   \n",
       "3        Arkansas          All Ages  2020              26.769   \n",
       "4      California          All Ages  2020              18.699   \n",
       "..            ...               ...   ...                 ...   \n",
       "46       Virginia  Youth (Under 18)  2023              31.657   \n",
       "47     Washington  Youth (Under 18)  2023              39.658   \n",
       "48  West Virginia  Youth (Under 18)  2023              42.339   \n",
       "49      Wisconsin  Youth (Under 18)  2023              33.397   \n",
       "50        Wyoming  Youth (Under 18)  2023              32.279   \n",
       "\n",
       "    Trauma Survivors  Suicidal Ideation   PTSD  Severe Depression  \\\n",
       "0             53.235             45.338 13.730             41.945   \n",
       "1             98.134             83.120 25.386             70.837   \n",
       "2             54.244             47.332 13.482             43.896   \n",
       "3             58.198             40.087 18.276             39.030   \n",
       "4             42.031             41.340 10.408             37.298   \n",
       "..               ...                ...    ...                ...   \n",
       "46           109.271             99.523 20.247             78.847   \n",
       "47           137.073            115.573 23.260             89.944   \n",
       "48           128.438             90.645 25.006             77.858   \n",
       "49           128.610             98.344 21.355             79.799   \n",
       "50           142.952            103.755 26.899             92.995   \n",
       "\n",
       "    Total Population  \n",
       "0            5039877  \n",
       "1             732673  \n",
       "2            7276316  \n",
       "3            3025891  \n",
       "4           39237836  \n",
       "..               ...  \n",
       "46           1866910  \n",
       "47           1646573  \n",
       "48            351922  \n",
       "49           1245629  \n",
       "50            130114  \n",
       "\n",
       "[600 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renamer = {\n",
    "    'Age1': 'Group',\n",
    "    'Year1': 'Year',\n",
    "    'Number of People At Possible Risk for Psychotic-Like Episodes': 'Psychotic Episodes',\n",
    "    'Number of People Identifying as Trauma Survivors': 'Trauma Survivors',\n",
    "    'Number of People Reporting Frequent Suicidal Ideation': 'Suicidal Ideation',\n",
    "    'Number of People Scoring Positive for PTSD': 'PTSD',\n",
    "    'Number of People Scoring with Severe Depression': 'Severe Depression'\n",
    "}\n",
    "\n",
    "to_keep = ['State', 'Group', 'Year',\n",
    "           'Psychotic Episodes', 'Trauma Survivors',\n",
    "           'Suicidal Ideation', 'PTSD',\n",
    "           'Severe Depression', 'Total Population']\n",
    "\n",
    "mh2020 = pd.read_csv('data/full_mh_2020.csv')\n",
    "mh2020 = mh2020.rename(renamer, axis=1)\n",
    "mh2020 = mh2020[(to_keep)]\n",
    "\n",
    "mh2021 = pd.read_csv('data/full_mh_2021.csv')\n",
    "mh2021 = mh2021.rename(renamer, axis=1)\n",
    "mh2021 = mh2021[(to_keep)]\n",
    "\n",
    "mh2022 = pd.read_csv('data/full_mh_2022.csv')\n",
    "mh2022 = mh2022.rename(renamer, axis=1)\n",
    "mh2022 = mh2022[(to_keep)]\n",
    "\n",
    "mh2023 = pd.read_csv('data/full_mh_2023.csv')\n",
    "mh2023 = mh2023.rename(renamer, axis=1)\n",
    "mh2023 = mh2023[(to_keep)]\n",
    "\n",
    "combined_20_23 = pd.concat([mh2020, mh2021], axis=0)\n",
    "combined_20_23 = pd.concat([combined_20_23, mh2022], axis=0)\n",
    "combined_20_23 = pd.concat([combined_20_23, mh2023], axis=0)\n",
    "\n",
    "dfs = []\n",
    "for year in ['2020', '2021', '2022', '2023']:\n",
    "    for age in ['adults', 'youth']:\n",
    "        filename = 'data/subgroups/mh_' + year + '_' + age + '_all.csv'\n",
    "        df_year_age = pd.read_csv(filename)\n",
    "        dfs.append(df_year_age)\n",
    "        #print(str(year) + ' ' + str(age) + ': ' + str(df_year_age.shape[0]))\n",
    "\n",
    "for df in dfs:\n",
    "    df = df.rename(renamer, axis=1)\n",
    "    df = df[(to_keep)]\n",
    "    combined_20_23 = pd.concat([combined_20_23, df], axis=0)\n",
    "\n",
    "combined_20_23 = combined_20_23[combined_20_23['State'] != 'District of Columbia']\n",
    "#combined_20_23 = combined_20_23.reset_index().drop(columns=['index'])\n",
    "#combined_melted = pd.melt(combined_20_23, id_vars=['State', 'Year', 'Group', 'Total Population'], value_vars=['Psychotic Episodes', 'Trauma Survivors', 'Suicidal Ideation', 'PTSD', 'Severe Depression'], var_name='Issue', value_name='# at Risk per 100K', ignore_index=False)\n",
    "#pd.concat([combined_20_23[['State', 'Group', 'Year', 'Total Population']],\n",
    "#          combined_melted.pivot(columns='Issue', values='# at Risk per 100K')], axis=1)\n",
    "#combined_melted\n",
    "combined_20_23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfdd55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Bill Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Florida</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Utah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Washington</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Bill Name\n",
       "0          Alabama          4\n",
       "1           Alaska          1\n",
       "2          Arizona          4\n",
       "3         Colorado          3\n",
       "4          Florida          2\n",
       "5          Georgia          3\n",
       "6            Idaho          3\n",
       "7         Illinois          1\n",
       "8          Indiana          4\n",
       "9             Iowa          7\n",
       "10          Kansas          1\n",
       "11        Kentucky          4\n",
       "12       Louisiana          1\n",
       "13   Massachusetts          1\n",
       "14     Mississippi          2\n",
       "15        Missouri          7\n",
       "16   New Hampshire          2\n",
       "17            Ohio          1\n",
       "18        Oklahoma          2\n",
       "19    Pennsylvania          1\n",
       "20  South Carolina          2\n",
       "21    South Dakota          4\n",
       "22       Tennessee         10\n",
       "23            Utah          1\n",
       "24      Washington          1\n",
       "25   West Virginia          2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2024=pd.read_csv('https://www.aclu.org/wp-json/api/legislation/csv/74348')\n",
    "\n",
    "df_2023=pd.read_csv('https://www.aclu.org/wp-json/api/legislation/csv/67497')\n",
    "df_2022=pd.read_csv('https://www.aclu.org/wp-content/uploads/2024/01/legislation-tracker_2022.csv')\n",
    "df_2021 = pd.read_csv('https://www.aclu.org/wp-content/uploads/2024/01/2021-legislation-tracker_2021.csv')\n",
    "df_2020 = pd.read_csv('https://www.aclu.org/wp-content/uploads/2024/01/legislation-tracker_2020.csv')\n",
    "\n",
    "aff_comp_protection = pd.read_csv(r'wrangling work/aff_compprotection', sep = '\\t', header = None)\n",
    "aff_health_care = pd.read_csv(r'wrangling work/aff_health_care', sep = '\\t', header = None)\n",
    "aff_ID_docs = pd.read_csv(r'wrangling work/aff_ID_docs', sep = '\\t', header = None)\n",
    "aff_incomplete_protection = pd.read_csv(r'wrangling work/aff_incomplete_2018', sep = '\\t', header = None)\n",
    "aff_other = pd.read_csv(r'wrangling work/aff_other', sep = '\\t', header = None)\n",
    "\n",
    "anti_adoption = pd.read_csv(r'wrangling work/anti_adoption', sep = '\\t', header = None)\n",
    "\n",
    "\n",
    "anti_FADA_and_religious_exemption=  pd.read_csv(r'wrangling work/anti_FADA_and_religious_exemption', sep = '\\t', header = None)\n",
    "anti_first_amend_def =  pd.read_csv(r'wrangling work/anti_first_amend_def', sep = '\\t', header = None)\n",
    "\n",
    "anti_health_care = pd.read_csv(r'wrangling work/anti_health_care', sep = '\\t', header = None)\n",
    "\n",
    "anti_marriage_rel_exemption =  pd.read_csv(r'wrangling work/anti_marriage_rel_exemption', sep = '\\t', header = None)\n",
    "\n",
    "anti_preempt_local_protection =  pd.read_csv(r'wrangling work/anti_preempt_local_protection', sep = '\\t', header = None)\n",
    "\n",
    "anti_religious_exemption_RFRA =  pd.read_csv(r'wrangling work/anti_religious_exemption_RFRA', sep = '\\t', header = None)\n",
    "\n",
    "anti_school_and_student_org =  pd.read_csv(r'wrangling work/anti_school_and_student_org', sep = '\\t', header = None)\n",
    "\n",
    "anti_single_sex_restrooms = pd.read_csv(r'wrangling work/anti_single_sex_restrooms', sep = '\\t', header = None)\n",
    "\n",
    "other_anti_lgbt = pd.read_csv(r'wrangling work/other_anti_lgbt', sep = '\\t', header = None)\n",
    "\n",
    "other_anti_trans =  pd.read_csv(r'wrangling work/other_anti_trans', sep = '\\t', header = None)\n",
    "\n",
    "other_rel_exemption = pd.read_csv(r'wrangling work/other_rel_exemption', sep = '\\t', header = None)\n",
    "#reading csv from text files that have pre 2020 data\n",
    "\n",
    "def make_df(tdf, which_type):\n",
    "    ind = 0\n",
    "    state=[]\n",
    "    number = []\n",
    "    status = []\n",
    "    for each in tdf[0]:\n",
    "        if ind % 3 == 0:\n",
    "            state.append(each)\n",
    "        elif ind % 3 == 1:\n",
    "            number.append(each)\n",
    "        else:\n",
    "            status.append(each)\n",
    "        ind += 1\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "\n",
    "    new_df['State'] = state\n",
    "    new_df['number'] = number\n",
    "    new_df['status'] = status\n",
    "\n",
    "    \n",
    "    dates = []\n",
    "    statuses = []\n",
    "    for status in new_df['status']:\n",
    "        parts = status.split(': ')\n",
    "        if len(parts) > 1:\n",
    "            dates.append(parts[0])\n",
    "            statuses.append(': '.join(parts[1:]))\n",
    "        else:\n",
    "            dates.append('')\n",
    "            statuses.append(parts[0])\n",
    "\n",
    "    new_df['Date'] = dates\n",
    "    new_df['status'] = statuses\n",
    "    new_df = new_df.assign(dtype = which_type)\n",
    "    \n",
    "    new_df = new_df.drop(0)\n",
    "\n",
    "    return new_df\n",
    "df_list = [aff_comp_protection, aff_health_care, aff_ID_docs, aff_incomplete_protection, aff_other, anti_adoption, \n",
    "            anti_FADA_and_religious_exemption, anti_first_amend_def, anti_health_care, anti_marriage_rel_exemption,\n",
    "            anti_preempt_local_protection, anti_religious_exemption_RFRA, anti_school_and_student_org,\n",
    "            anti_single_sex_restrooms, other_anti_lgbt, other_anti_trans, other_rel_exemption]\n",
    "df_names = ['aff_comp_protection', 'aff_health_care', 'aff_ID_docs', 'aff_incomplete_protection', 'aff_other', 'anti_adoption', \n",
    "            'anti_FADA_and_religious_exemption', 'anti_first_amend_def', 'anti_health_care', 'anti_marriage_rel_exemption',\n",
    "            'anti_preempt_local_protection', 'anti_religious_exemption_RFRA', 'anti_school_and_student_org',\n",
    "            'anti_single_sex_restrooms', 'other_anti_lgbt', 'other_anti_trans', 'other_rel_exemption']\n",
    "for each, name in zip(df_list, df_names):\n",
    "    \n",
    "    try:\n",
    "        each = make_df(each, name)\n",
    "        \n",
    "    except:\n",
    "        print(name)\n",
    "        \n",
    "#identifies which ones are messed up \n",
    "\n",
    "dfs = {}\n",
    "\n",
    "# Loop through each element in the list\n",
    "for each, name in zip(df_list, df_names):\n",
    "    # Generate DataFrame for the current element\n",
    "    new_df = make_df(each, name)\n",
    "    \n",
    "    # Store the DataFrame in the dictionary with element as key\n",
    "    dfs[name] = new_df\n",
    "    \n",
    "combined_df = pd.concat(dfs.values(), ignore_index=True)\n",
    "\n",
    "combined_df = combined_df[combined_df['State'] != 'State'] #remove invalid rows\n",
    "#this is the combined df of all the ones we had to pull from text data. Further cleaning will involve combining all\n",
    "status_index = df_2022.columns.get_loc('Status ')\n",
    "\n",
    "# Insert the 'Status Detail' column right after the 'Status' column\n",
    "df_2022.insert(status_index + 1, 'Status Detail', np.nan)\n",
    "\n",
    "df_2020 = df_2020.reset_index()\n",
    "df_2020.columns = df_2020.iloc[0]\n",
    "df_2020 = df_2020.drop(df_2020.index[0])\n",
    "df_2020['Year'] = 2020\n",
    "df_2021['Year'] = 2021\n",
    "df_2022['Year'] = 2022\n",
    "df_2023['Year'] = 2023\n",
    "df_2024['Year'] = 2024\n",
    "\n",
    "\n",
    "website_csv= [df_2024, df_2022, df_2023, df_2021, df_2020]\n",
    "for each in website_csv:\n",
    "    each.columns = each.columns.str.strip()\n",
    "\n",
    "\n",
    "combined_web = pd.concat(website_csv)\n",
    "combined_web = combined_web.dropna(thresh=2)\n",
    "#since we gave all of them a default 'year' value, this deletes rows where this default column is the only data\n",
    "combined_web = combined_web.reset_index()\n",
    "\n",
    "combined_web = combined_web.drop(index = [1457, 1456])\n",
    "state_mapping = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "    'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri',\n",
    "    'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "combined_web['State'] = combined_web['State'].str.strip()\n",
    "combined_web['State'] = combined_web['State'].replace(state_mapping)\n",
    "combined_web['State'] = combined_web['State'].replace('New England', 'Nebraska')\n",
    "#whoever made this csv initially confused them for some reason? ig NE looks like new england\n",
    "combined_web = combined_web[~combined_web.apply(lambda row: row.astype(str).str.contains('Data is current').any(), axis=1)]\n",
    "anti_web_df =  combined_web[~combined_web['Issues'].astype(str).str.contains('LGBTQ Equality Bills')]\n",
    "anti_web_df =  anti_web_df[~anti_web_df['Issues'].astype(str).str.contains('good bills')]\n",
    "#anti_web_df['Status Date'] = pd.to_datetime(anti_web_df['Status Date'])\n",
    "\n",
    "excluding_duplicates = anti_web_df.groupby('State')[\"Bill Name\"].nunique()\n",
    "excluding_duplicates = excluding_duplicates.reset_index()\n",
    "#makes a df of the number of unique bills per state, so that there aren't repeats \n",
    "\n",
    "merged_df = pd.merge(combined_20_23, excluding_duplicates[['State', 'Bill Name']], on='State', how='left')\n",
    "merged_df = merged_df.rename(columns = {'Bill Name': 'Number of bills'})\n",
    "\n",
    "bills_2020 = anti_web_df[anti_web_df['Year'] == 2020]\n",
    "bills_2021 = anti_web_df[anti_web_df['Year'] == 2021]\n",
    "bills_2022 = anti_web_df[anti_web_df['Year'] == 2022]\n",
    "bills_2023 = anti_web_df[anti_web_df['Year'] == 2023]\n",
    "bills_2024 = anti_web_df[anti_web_df['Year'] == 2024]\n",
    "count_state_2020 = bills_2020.groupby('State')['Bill Name'].nunique().reset_index()\n",
    "count_state_2021 = bills_2021.groupby('State')['Bill Name'].nunique().reset_index()\n",
    "count_state_2022 = bills_2022.groupby('State')['Bill Name'].nunique().reset_index()\n",
    "count_state_2023 = bills_2023.groupby('State')['Bill Name'].nunique().reset_index()\n",
    "count_state_2024 = bills_2024.groupby('State')['Bill Name'].nunique().reset_index()\n",
    "merged_20 = pd.merge(mh2020, count_state_2020[['State', 'Bill Name']], on='State', how='left')\n",
    "merged_21 = pd.merge(mh2021, count_state_2021[['State', 'Bill Name']], on='State', how='left')\n",
    "merged_22 = pd.merge(mh2022, count_state_2022[['State', 'Bill Name']], on='State', how='left')\n",
    "merged_23 = pd.merge(mh2023, count_state_2023[['State', 'Bill Name']], on='State', how='left')\n",
    "\n",
    "merged_list = [merged_20, merged_21, merged_22, merged_23]\n",
    "for df in merged_list:\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.rename(columns={'Bill Name': 'Number', 'Severe Depression': 'Severe_Depression', 'Psychotic Episodes':'Psychotic_ep',\n",
    "                       'Trauma Survivors': 'Trauma', 'Suicidal Ideation' :'Suicidal_Ideation'}, inplace=True)\n",
    "'''merged_20 = merged_20[merged_20['State'] != 'Alaska']\n",
    "merged_21 = merged_21[merged_21['State'] != 'Alaska']\n",
    "merged_22 = merged_22[merged_22['State'] != 'Alaska']\n",
    "merged_23 = merged_23[merged_23['State'] != 'Alaska']'''\n",
    "\n",
    "count_state_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2dae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "filler = pd.DataFrame(state_names).assign(Count = 0).rename({0: 'State'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3311a87a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maine</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Montana</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New York</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Texas</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Utah</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Year  Count\n",
       "0          Alabama  2020      4\n",
       "1           Alaska  2020      1\n",
       "2          Arizona  2020      4\n",
       "3         Arkansas  2020      0\n",
       "4       California  2020      0\n",
       "5         Colorado  2020      3\n",
       "6      Connecticut  2020      0\n",
       "7         Delaware  2020      0\n",
       "8          Florida  2020      2\n",
       "9          Georgia  2020      3\n",
       "10          Hawaii  2020      0\n",
       "11           Idaho  2020      3\n",
       "12        Illinois  2020      1\n",
       "13         Indiana  2020      4\n",
       "14            Iowa  2020      7\n",
       "15          Kansas  2020      1\n",
       "16        Kentucky  2020      4\n",
       "17       Louisiana  2020      1\n",
       "18           Maine  2020      0\n",
       "19        Maryland  2020      0\n",
       "20   Massachusetts  2020      1\n",
       "21        Michigan  2020      0\n",
       "22       Minnesota  2020      0\n",
       "23     Mississippi  2020      2\n",
       "24        Missouri  2020      7\n",
       "25         Montana  2020      0\n",
       "26        Nebraska  2020      0\n",
       "27          Nevada  2020      0\n",
       "28   New Hampshire  2020      2\n",
       "29      New Jersey  2020      0\n",
       "30      New Mexico  2020      0\n",
       "31        New York  2020      0\n",
       "32  North Carolina  2020      0\n",
       "33    North Dakota  2020      0\n",
       "34            Ohio  2020      1\n",
       "35        Oklahoma  2020      2\n",
       "36          Oregon  2020      0\n",
       "37    Pennsylvania  2020      1\n",
       "38    Rhode Island  2020      0\n",
       "39  South Carolina  2020      2\n",
       "40    South Dakota  2020      4\n",
       "41       Tennessee  2020     10\n",
       "42           Texas  2020      0\n",
       "43            Utah  2020      1\n",
       "44         Vermont  2020      0\n",
       "45        Virginia  2020      0\n",
       "46      Washington  2020      1\n",
       "47   West Virginia  2020      2\n",
       "48       Wisconsin  2020      0\n",
       "49         Wyoming  2020      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws_20 = count_state_2020\n",
    "laws_20 = laws_20.rename({'Bill Name': 'Bills'}, axis=1)\n",
    "laws_20_full = filler.merge(laws_20, on='State', how='left')\n",
    "laws_20_full['Count'] = laws_20_full['Count'] + laws_20_full['Bills']\n",
    "laws_20_full['Count'] = laws_20_full['Count'].apply(clear_nan)\n",
    "laws_20_full = laws_20_full.drop(columns=['Bills'])\n",
    "laws_20_full['Year'] = 2020\n",
    "laws_20_full = laws_20_full[['State', 'Year', 'Count']]\n",
    "laws_20_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6633a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maine</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Montana</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New York</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Texas</td>\n",
       "      <td>2021</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Utah</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Year  Count\n",
       "0          Alabama  2021      4\n",
       "1           Alaska  2021      0\n",
       "2          Arizona  2021      4\n",
       "3         Arkansas  2021     12\n",
       "4       California  2021      0\n",
       "5         Colorado  2021      0\n",
       "6      Connecticut  2021      2\n",
       "7         Delaware  2021      0\n",
       "8          Florida  2021      4\n",
       "9          Georgia  2021      4\n",
       "10          Hawaii  2021      1\n",
       "11           Idaho  2021      0\n",
       "12        Illinois  2021      0\n",
       "13         Indiana  2021      4\n",
       "14            Iowa  2021      8\n",
       "15          Kansas  2021      2\n",
       "16        Kentucky  2021      6\n",
       "17       Louisiana  2021      4\n",
       "18           Maine  2021      1\n",
       "19        Maryland  2021      1\n",
       "20   Massachusetts  2021      0\n",
       "21        Michigan  2021      1\n",
       "22       Minnesota  2021      3\n",
       "23     Mississippi  2021      2\n",
       "24        Missouri  2021     11\n",
       "25         Montana  2021      5\n",
       "26        Nebraska  2021      0\n",
       "27          Nevada  2021      0\n",
       "28   New Hampshire  2021      2\n",
       "29      New Jersey  2021      1\n",
       "30      New Mexico  2021      2\n",
       "31        New York  2021      0\n",
       "32  North Carolina  2021      2\n",
       "33    North Dakota  2021      2\n",
       "34            Ohio  2021      4\n",
       "35        Oklahoma  2021      7\n",
       "36          Oregon  2021      0\n",
       "37    Pennsylvania  2021      1\n",
       "38    Rhode Island  2021      0\n",
       "39  South Carolina  2021      8\n",
       "40    South Dakota  2021      4\n",
       "41       Tennessee  2021     11\n",
       "42           Texas  2021     16\n",
       "43            Utah  2021      3\n",
       "44         Vermont  2021      0\n",
       "45        Virginia  2021      0\n",
       "46      Washington  2021      0\n",
       "47   West Virginia  2021      8\n",
       "48       Wisconsin  2021      6\n",
       "49         Wyoming  2021      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws_21 = count_state_2021\n",
    "laws_21 = laws_21.rename({'Bill Name': 'Bills'}, axis=1)\n",
    "laws_21['Bills'] = laws_21['Bills'].apply(int)\n",
    "laws_21_full = filler.merge(laws_21, on='State', how='left')\n",
    "laws_21_full['Count'] = laws_21_full['Count'] + laws_21_full['Bills']\n",
    "laws_21_full['Count'] = laws_21_full['Count'].apply(clear_nan)\n",
    "laws_21_full = laws_21_full.drop(columns=['Bills'])\n",
    "#np.count_nonzero(laws_21_full['Count'])\n",
    "laws_21_full['Year'] = 2021\n",
    "laws_21_full = laws_21_full[['State', 'Year', 'Count']]\n",
    "laws_21_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7afb6fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maine</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>2022</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Montana</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New York</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2022</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>2022</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2022</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Texas</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Utah</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>2022</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Year  Count\n",
       "0          Alabama  2022      6\n",
       "1           Alaska  2022      3\n",
       "2          Arizona  2022     12\n",
       "3         Arkansas  2022      0\n",
       "4       California  2022      1\n",
       "5         Colorado  2022      0\n",
       "6      Connecticut  2022      0\n",
       "7         Delaware  2022      2\n",
       "8          Florida  2022      6\n",
       "9          Georgia  2022      6\n",
       "10          Hawaii  2022      4\n",
       "11           Idaho  2022      2\n",
       "12        Illinois  2022      4\n",
       "13         Indiana  2022      8\n",
       "14            Iowa  2022     12\n",
       "15          Kansas  2022      4\n",
       "16        Kentucky  2022      8\n",
       "17       Louisiana  2022      3\n",
       "18           Maine  2022      0\n",
       "19        Maryland  2022      1\n",
       "20   Massachusetts  2022      2\n",
       "21        Michigan  2022      5\n",
       "22       Minnesota  2022      5\n",
       "23     Mississippi  2022      8\n",
       "24        Missouri  2022     16\n",
       "25         Montana  2022      0\n",
       "26        Nebraska  2022      3\n",
       "27          Nevada  2022      0\n",
       "28   New Hampshire  2022      4\n",
       "29      New Jersey  2022      8\n",
       "30      New Mexico  2022      0\n",
       "31        New York  2022      4\n",
       "32  North Carolina  2022      2\n",
       "33    North Dakota  2022      0\n",
       "34            Ohio  2022      5\n",
       "35        Oklahoma  2022     15\n",
       "36          Oregon  2022      0\n",
       "37    Pennsylvania  2022      4\n",
       "38    Rhode Island  2022      6\n",
       "39  South Carolina  2022     13\n",
       "40    South Dakota  2022      3\n",
       "41       Tennessee  2022     15\n",
       "42           Texas  2022      0\n",
       "43            Utah  2022      3\n",
       "44         Vermont  2022      3\n",
       "45        Virginia  2022      5\n",
       "46      Washington  2022      4\n",
       "47   West Virginia  2022     13\n",
       "48       Wisconsin  2022      8\n",
       "49         Wyoming  2022      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws_22 = count_state_2022\n",
    "laws_22 = laws_22.rename({'Bill Name': 'Bills'}, axis=1)\n",
    "laws_22['Bills'] = laws_22['Bills'].apply(int)\n",
    "laws_22_full = filler.merge(laws_22, on='State', how='left')\n",
    "laws_22_full['Count'] = laws_22_full['Count'] + laws_22_full['Bills']\n",
    "laws_22_full['Count'] = laws_22_full['Count'].apply(clear_nan)\n",
    "laws_22_full = laws_22_full.drop(columns=['Bills'])\n",
    "#np.count_nonzero(laws_22_full['Count'])\n",
    "laws_22_full['Year'] = 2022\n",
    "laws_22_full = laws_22_full[['State', 'Year', 'Count']]\n",
    "laws_22_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d761117d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Florida</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>2023</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>2023</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>2023</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Maine</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2023</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>2023</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Montana</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New York</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2023</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>2023</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>2023</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2023</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Texas</td>\n",
       "      <td>2023</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Utah</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Washington</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2023</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2023</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Year  Count\n",
       "0          Alabama  2023      6\n",
       "1           Alaska  2023      5\n",
       "2          Arizona  2023     11\n",
       "3         Arkansas  2023      9\n",
       "4       California  2023      1\n",
       "5         Colorado  2023      1\n",
       "6      Connecticut  2023      2\n",
       "7         Delaware  2023      0\n",
       "8          Florida  2023     10\n",
       "9          Georgia  2023      5\n",
       "10          Hawaii  2023      5\n",
       "11           Idaho  2023      8\n",
       "12        Illinois  2023      0\n",
       "13         Indiana  2023     18\n",
       "14            Iowa  2023     29\n",
       "15          Kansas  2023     14\n",
       "16        Kentucky  2023     11\n",
       "17       Louisiana  2023      4\n",
       "18           Maine  2023      2\n",
       "19        Maryland  2023      1\n",
       "20   Massachusetts  2023      2\n",
       "21        Michigan  2023      9\n",
       "22       Minnesota  2023     10\n",
       "23     Mississippi  2023     25\n",
       "24        Missouri  2023     48\n",
       "25         Montana  2023      8\n",
       "26        Nebraska  2023      4\n",
       "27          Nevada  2023      2\n",
       "28   New Hampshire  2023      4\n",
       "29      New Jersey  2023      6\n",
       "30      New Mexico  2023      1\n",
       "31        New York  2023      0\n",
       "32  North Carolina  2023     11\n",
       "33    North Dakota  2023     17\n",
       "34            Ohio  2023      7\n",
       "35        Oklahoma  2023     35\n",
       "36          Oregon  2023      7\n",
       "37    Pennsylvania  2023      3\n",
       "38    Rhode Island  2023      5\n",
       "39  South Carolina  2023     20\n",
       "40    South Dakota  2023      3\n",
       "41       Tennessee  2023     26\n",
       "42           Texas  2023     55\n",
       "43            Utah  2023      9\n",
       "44         Vermont  2023      2\n",
       "45        Virginia  2023     12\n",
       "46      Washington  2023      2\n",
       "47   West Virginia  2023     12\n",
       "48       Wisconsin  2023     15\n",
       "49         Wyoming  2023      6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws_23 = count_state_2023\n",
    "laws_23 = laws_23.rename({'Bill Name': 'Bills'}, axis=1)\n",
    "laws_23['Bills'] = laws_23['Bills'].apply(int)\n",
    "laws_23_full = filler.merge(laws_23, on='State', how='left')\n",
    "laws_23_full['Count'] = laws_23_full['Count'] + laws_23_full['Bills']\n",
    "laws_23_full['Count'] = laws_23_full['Count'].apply(clear_nan)\n",
    "laws_23_full = laws_23_full.drop(columns=['Bills'])\n",
    "#np.count_nonzero(laws_23_full['Count'])\n",
    "laws_23_full['Year'] = 2023\n",
    "laws_23_full = laws_23_full[['State', 'Year', 'Count']]\n",
    "laws_23_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca14efc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Group</th>\n",
       "      <th>Year</th>\n",
       "      <th>Psychotic Episodes</th>\n",
       "      <th>Trauma Survivors</th>\n",
       "      <th>Suicidal Ideation</th>\n",
       "      <th>PTSD</th>\n",
       "      <th>Severe Depression</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>29.088</td>\n",
       "      <td>53.235</td>\n",
       "      <td>45.338</td>\n",
       "      <td>13.730</td>\n",
       "      <td>41.945</td>\n",
       "      <td>5039877</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>49.545</td>\n",
       "      <td>98.134</td>\n",
       "      <td>83.120</td>\n",
       "      <td>25.386</td>\n",
       "      <td>70.837</td>\n",
       "      <td>732673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>25.411</td>\n",
       "      <td>54.244</td>\n",
       "      <td>47.332</td>\n",
       "      <td>13.482</td>\n",
       "      <td>43.896</td>\n",
       "      <td>7276316</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>26.769</td>\n",
       "      <td>58.198</td>\n",
       "      <td>40.087</td>\n",
       "      <td>18.276</td>\n",
       "      <td>39.030</td>\n",
       "      <td>3025891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>All Ages</td>\n",
       "      <td>2020</td>\n",
       "      <td>18.699</td>\n",
       "      <td>42.031</td>\n",
       "      <td>41.340</td>\n",
       "      <td>10.408</td>\n",
       "      <td>37.298</td>\n",
       "      <td>39237836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>31.657</td>\n",
       "      <td>109.271</td>\n",
       "      <td>99.523</td>\n",
       "      <td>20.247</td>\n",
       "      <td>78.847</td>\n",
       "      <td>1866910</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Washington</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>39.658</td>\n",
       "      <td>137.073</td>\n",
       "      <td>115.573</td>\n",
       "      <td>23.260</td>\n",
       "      <td>89.944</td>\n",
       "      <td>1646573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>42.339</td>\n",
       "      <td>128.438</td>\n",
       "      <td>90.645</td>\n",
       "      <td>25.006</td>\n",
       "      <td>77.858</td>\n",
       "      <td>351922</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>33.397</td>\n",
       "      <td>128.610</td>\n",
       "      <td>98.344</td>\n",
       "      <td>21.355</td>\n",
       "      <td>79.799</td>\n",
       "      <td>1245629</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Youth (Under 18)</td>\n",
       "      <td>2023</td>\n",
       "      <td>32.279</td>\n",
       "      <td>142.952</td>\n",
       "      <td>103.755</td>\n",
       "      <td>26.899</td>\n",
       "      <td>92.995</td>\n",
       "      <td>130114</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             State             Group  Year  Psychotic Episodes  \\\n",
       "0          Alabama          All Ages  2020              29.088   \n",
       "1           Alaska          All Ages  2020              49.545   \n",
       "2          Arizona          All Ages  2020              25.411   \n",
       "3         Arkansas          All Ages  2020              26.769   \n",
       "4       California          All Ages  2020              18.699   \n",
       "..             ...               ...   ...                 ...   \n",
       "595       Virginia  Youth (Under 18)  2023              31.657   \n",
       "596     Washington  Youth (Under 18)  2023              39.658   \n",
       "597  West Virginia  Youth (Under 18)  2023              42.339   \n",
       "598      Wisconsin  Youth (Under 18)  2023              33.397   \n",
       "599        Wyoming  Youth (Under 18)  2023              32.279   \n",
       "\n",
       "     Trauma Survivors  Suicidal Ideation   PTSD  Severe Depression  \\\n",
       "0              53.235             45.338 13.730             41.945   \n",
       "1              98.134             83.120 25.386             70.837   \n",
       "2              54.244             47.332 13.482             43.896   \n",
       "3              58.198             40.087 18.276             39.030   \n",
       "4              42.031             41.340 10.408             37.298   \n",
       "..                ...                ...    ...                ...   \n",
       "595           109.271             99.523 20.247             78.847   \n",
       "596           137.073            115.573 23.260             89.944   \n",
       "597           128.438             90.645 25.006             77.858   \n",
       "598           128.610             98.344 21.355             79.799   \n",
       "599           142.952            103.755 26.899             92.995   \n",
       "\n",
       "     Total Population  Count  \n",
       "0             5039877      4  \n",
       "1              732673      1  \n",
       "2             7276316      4  \n",
       "3             3025891      0  \n",
       "4            39237836      0  \n",
       "..                ...    ...  \n",
       "595           1866910     12  \n",
       "596           1646573      2  \n",
       "597            351922     12  \n",
       "598           1245629     15  \n",
       "599            130114      6  \n",
       "\n",
       "[600 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laws_full_all = [laws_20_full, laws_21_full, laws_22_full, laws_23_full]\n",
    "law_count_df = pd.concat(laws_full_all, axis=0)\n",
    "mh_laws = combined_20_23[combined_20_23['State'].apply(keep_state)].merge(law_count_df, on=['State', 'Year'], how='left')\n",
    "mh_laws#[(mh_laws['Year'] == 2023) & (mh_laws['State'] == 'Missouri')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b10c63",
   "metadata": {},
   "source": [
    "# FACILITY DATA 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab43cdef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1874\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1873\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1874\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:849\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    847\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:877\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 877\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[1;32m    878\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:2380\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 2380\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[1;32m   2381\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2382\u001b[0m     )\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:6225\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6217\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6223\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6224\u001b[0m ):\n\u001b[0;32m-> 6225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11992\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11986\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11987\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11990\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11991\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  11993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  11994\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  11950\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11951\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:6133\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6132\u001b[0m     )\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:1693\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string 'All AgesAll AgesAll AgesAll AgesAdults (Over 18)Youth (Under 18)Adults (Over 18)Youth (Under 18)Adults (Over 18)Youth (Under 18)Adults (Over 18)Youth (Under 18)' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m facilities_df \u001b[38;5;241m=\u001b[39m facilities_df\u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLGBTQ Treatment Program\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgLGBT\u001b[39m\u001b[38;5;124m'\u001b[39m}, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m facilities_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([facilities_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFacility Type\u001b[39m\u001b[38;5;124m'\u001b[39m]], facilities_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProgLGBT\u001b[39m\u001b[38;5;124m'\u001b[39m]]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m facilities_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([facilities_df, pd\u001b[38;5;241m.\u001b[39mDataFrame(combined_20_23\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Population\u001b[39m\u001b[38;5;124m'\u001b[39m])], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m facilities_df \u001b[38;5;241m=\u001b[39m facilities_df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m facilities_df \u001b[38;5;241m=\u001b[39m facilities_df\u001b[38;5;241m.\u001b[39mrename({\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFacility Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountFacility\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     50\u001b[0m }, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:2378\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   2372\u001b[0m         grouped_mean,\n\u001b[1;32m   2373\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[1;32m   2374\u001b[0m         engine_kwargs,\n\u001b[1;32m   2375\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2376\u001b[0m     )\n\u001b[1;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2380\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[1;32m   2381\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2382\u001b[0m     )\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1929\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1929\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[1;32m   1930\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   1931\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1428\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[0;32m-> 1428\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[1;32m   1429\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:366\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    368\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1926\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1926\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1878\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1877\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[0;32m-> 1878\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m   1881\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import csv \n",
    "facilities_df = pd.read_csv('mental_health_facilities.csv')\n",
    "\n",
    "#keep relevant columns\n",
    "keep_cols = ['LST', 'FACILITYTYPE', 'FOCUS', 'SRVC62', 'PAYASST', 'REVCHK1']\n",
    "facilities_df = facilities_df[keep_cols]\n",
    "facilities_df = facilities_df.rename(columns={'LST': 'State', 'FACILITYTYPE': 'Facility Type', 'FOCUS': 'Focus', 'PAYASST': 'Pay Assist', 'SRVC62': 'LGBTQ Treatment Program', 'REVCHK1': 'Accepts Cash Payment' })\n",
    "\n",
    "facility_type_mapping = {\n",
    "    1: 'Psychiatric hospital',\n",
    "    2: 'Separate inpatient unit',\n",
    "    3: 'Residential treatment center for children',\n",
    "    4: 'Residential treatment center for adults',\n",
    "    5: 'Other type of residential treatment facility',\n",
    "    6: 'Veterans Administration Medical Center',\n",
    "    7: 'Community Mental Health Center',\n",
    "    8: 'Certified Community Behaviorial Health Clinic',\n",
    "    9: 'Partial hospitalization/day treatment facility',\n",
    "    10: 'Outpatient mental health facility',\n",
    "    11: 'Multi-setting mental health facility',\n",
    "    12: 'Other'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'facility type' column\n",
    "facilities_df['Facility Type'] = facilities_df['Facility Type'].map(facility_type_mapping)\n",
    "\n",
    "\n",
    "focus_mapping = {\n",
    "    1: 'Mental health treatment',\n",
    "    3: 'Mental health and substance use treatment',\n",
    "    4: 'General heath care',\n",
    "    5: 'Other service focus'\n",
    "\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'focus' column\n",
    "facilities_df['Focus'] = facilities_df['Focus'].map(focus_mapping)\n",
    "\n",
    "#Drop any facilities that are have state code 'ZZ' because this means that the location is unknown\n",
    "facilities_df = facilities_df[~(facilities_df['State'] == 'ZZ')]\n",
    "facilities_df['State'] = facilities_df['State'].replace(state_mapping)\n",
    "facilities_df = facilities_df.rename({'LGBTQ Treatment Program': 'ProgLGBT'}, axis=1)\n",
    "facilities_df = pd.concat([facilities_df.groupby('State').count()[['Facility Type']], facilities_df.groupby('State').sum()[['ProgLGBT']]], axis=1)\n",
    "facilities_df = pd.concat([facilities_df, pd.DataFrame(combined_20_23.groupby('State').mean()['Total Population'])], axis=1)\n",
    "facilities_df = facilities_df.dropna(axis=0)\n",
    "facilities_df = facilities_df.rename({\n",
    "    'Facility Type': 'CountFacility'\n",
    "}, axis=1)\n",
    "facilities_df['CountFacility'] = facilities_df['CountFacility'] / facilities_df['Total Population'] * 100000\n",
    "facilities_df['ProgLGBT'] = facilities_df['ProgLGBT'] / facilities_df['Total Population'] * 100000\n",
    "facilities_df = facilities_df.drop(columns='Total Population').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224d5732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/ljwlvg0x5pv9zsh8tkrhq7b40000gn/T/ipykernel_7111/985576115.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mh_df.rename({'Count': 'CountLaws'}, axis=1, inplace=True)\n",
      "/var/folders/4r/ljwlvg0x5pv9zsh8tkrhq7b40000gn/T/ipykernel_7111/985576115.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mh_df.rename(columns = {'Bill Name': 'NumberBills',\n"
     ]
    }
   ],
   "source": [
    "mh_laws_20_all = mh_laws[(mh_laws['Year'] == 2020) & (mh_laws['Group'] == 'All Ages')]\n",
    "mh_laws_21_all = mh_laws[(mh_laws['Year'] == 2021) & (mh_laws['Group'] == 'All Ages')]\n",
    "mh_laws_22_all = mh_laws[(mh_laws['Year'] == 2022) & (mh_laws['Group'] == 'All Ages')]\n",
    "mh_laws_23_all = mh_laws[(mh_laws['Year'] == 2023) & (mh_laws['Group'] == 'All Ages')]\n",
    "\n",
    "mh_laws_20_youth = mh_laws[(mh_laws['Year'] == 2020) & (mh_laws['Group'] == 'Youth (Under 18)')]\n",
    "mh_laws_21_youth = mh_laws[(mh_laws['Year'] == 2021) & (mh_laws['Group'] == 'Youth (Under 18)')]\n",
    "mh_laws_22_youth = mh_laws[(mh_laws['Year'] == 2022) & (mh_laws['Group'] == 'Youth (Under 18)')]\n",
    "mh_laws_23_youth = mh_laws[(mh_laws['Year'] == 2023) & (mh_laws['Group'] == 'Youth (Under 18)')]\n",
    "\n",
    "mh_laws_20_adult = mh_laws[(mh_laws['Year'] == 2020) & (mh_laws['Group'] == 'Adults (Over 18)')]\n",
    "mh_laws_21_adult = mh_laws[(mh_laws['Year'] == 2021) & (mh_laws['Group'] == 'Adults (Over 18)')]\n",
    "mh_laws_22_adult = mh_laws[(mh_laws['Year'] == 2022) & (mh_laws['Group'] == 'Adults (Over 18)')]\n",
    "mh_laws_23_adult = mh_laws[(mh_laws['Year'] == 2023) & (mh_laws['Group'] == 'Adults (Over 18)')]\n",
    "\n",
    "mh_laws_20_all = mh_laws_20_all.merge(facilities_df, on='State', how='left')\n",
    "\n",
    "mh_laws_20_youth = mh_laws_20_youth.merge(facilities_df, on='State', how='left')\n",
    "\n",
    "mh_laws_20_adult = mh_laws_20_adult.merge(facilities_df, on='State', how='left')\n",
    "\n",
    "mh_dfs = [\n",
    "    mh_laws_20_all,\n",
    "    mh_laws_20_youth,\n",
    "    mh_laws_20_adult,\n",
    "    mh_laws_21_all,\n",
    "    mh_laws_21_youth,\n",
    "    mh_laws_21_adult,\n",
    "    mh_laws_22_all,\n",
    "    mh_laws_22_youth,\n",
    "    mh_laws_22_adult,\n",
    "    mh_laws_23_all,\n",
    "    mh_laws_23_youth,\n",
    "    mh_laws_23_adult\n",
    "]\n",
    "\n",
    "for mh_df in mh_dfs:\n",
    "    mh_df.rename({'Count': 'CountLaws'}, axis=1, inplace=True)\n",
    "    mh_df.rename(columns = {'Bill Name': 'NumberBills',\n",
    "                                       'Psychotic Episodes': 'Psychotic',\n",
    "                                       'Trauma Survivors': 'Trauma',\n",
    "                                       'Suicidal Ideation': 'SuicidalIdea',\n",
    "                                       'Severe Depression': 'Depression'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7475cf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'CountFacility' is not defined\n    Psychotic ~ CountLaws + CountFacility\n                            ^^^^^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/compat.py:36\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/eval.py:169\u001b[0m, in \u001b[0;36mEvalEnvironment.eval\u001b[0;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[1;32m    168\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcompile\u001b[39m(expr, source_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28meval\u001b[39m(code, {}, VarLookupDict([inner_namespace]\n\u001b[1;32m    170\u001b[0m                                     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespaces))\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CountFacility' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m issue \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(mh_issues):\n\u001b[1;32m      8\u001b[0m     arg \u001b[38;5;241m=\u001b[39m issue \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ~ CountLaws + CountFacility\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     outcome, predictors \u001b[38;5;241m=\u001b[39m patsy\u001b[38;5;241m.\u001b[39mdmatrices(arg, group)\n\u001b[1;32m     10\u001b[0m     mod \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mOLS(outcome, predictors)  \n\u001b[1;32m     11\u001b[0m     res \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/highlevel.py:309\u001b[0m, in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m EvalEnvironment\u001b[38;5;241m.\u001b[39mcapture(eval_env, reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 309\u001b[0m (lhs, rhs) \u001b[38;5;241m=\u001b[39m _do_highlevel_design(formula_like, data, eval_env,\n\u001b[1;32m    310\u001b[0m                                   NA_action, return_type)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lhs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is missing required outcome variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/highlevel.py:164\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_iter_maker\u001b[39m():\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m([data])\n\u001b[0;32m--> 164\u001b[0m design_infos \u001b[38;5;241m=\u001b[39m _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[1;32m    165\u001b[0m                                   NA_action)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m design_infos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build_design_matrices(design_infos, data,\n\u001b[1;32m    168\u001b[0m                                  NA_action\u001b[38;5;241m=\u001b[39mNA_action,\n\u001b[1;32m    169\u001b[0m                                  return_type\u001b[38;5;241m=\u001b[39mreturn_type)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/highlevel.py:66\u001b[0m, in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formula_like, ModelDesc):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_env, EvalEnvironment)\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m design_matrix_builders([formula_like\u001b[38;5;241m.\u001b[39mlhs_termlist,\n\u001b[1;32m     67\u001b[0m                                    formula_like\u001b[38;5;241m.\u001b[39mrhs_termlist],\n\u001b[1;32m     68\u001b[0m                                   data_iter_maker,\n\u001b[1;32m     69\u001b[0m                                   eval_env,\n\u001b[1;32m     70\u001b[0m                                   NA_action)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/build.py:693\u001b[0m, in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    689\u001b[0m factor_states \u001b[38;5;241m=\u001b[39m _factors_memorize(all_factors, data_iter_maker, eval_env)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;66;03m# Now all the factors have working eval methods, so we can evaluate them\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;66;03m# on some data to find out what type of data they return.\u001b[39;00m\n\u001b[1;32m    692\u001b[0m (num_column_counts,\n\u001b[0;32m--> 693\u001b[0m  cat_levels_contrasts) \u001b[38;5;241m=\u001b[39m _examine_factor_types(all_factors,\n\u001b[1;32m    694\u001b[0m                                                factor_states,\n\u001b[1;32m    695\u001b[0m                                                data_iter_maker,\n\u001b[1;32m    696\u001b[0m                                                NA_action)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;66;03m# Now we need the factor infos, which encapsulate the knowledge of\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# how to turn any given factor into a chunk of data:\u001b[39;00m\n\u001b[1;32m    699\u001b[0m factor_infos \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/build.py:443\u001b[0m, in \u001b[0;36m_examine_factor_types\u001b[0;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m data_iter_maker():\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m factor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(examine_needed):\n\u001b[0;32m--> 443\u001b[0m         value \u001b[38;5;241m=\u001b[39m factor\u001b[38;5;241m.\u001b[39meval(factor_states[factor], data)\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m factor \u001b[38;5;129;01min\u001b[39;00m cat_sniffers \u001b[38;5;129;01mor\u001b[39;00m guess_categorical(value):\n\u001b[1;32m    445\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m factor \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cat_sniffers:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/eval.py:568\u001b[0m, in \u001b[0;36mEvalFactor.eval\u001b[0;34m(self, memorize_state, data)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, memorize_state, data):\n\u001b[0;32m--> 568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval(memorize_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_code\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    569\u001b[0m                       memorize_state,\n\u001b[1;32m    570\u001b[0m                       data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/eval.py:551\u001b[0m, in \u001b[0;36mEvalFactor._eval\u001b[0;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_eval\u001b[39m(\u001b[38;5;28mself\u001b[39m, code, memorize_state, data):\n\u001b[1;32m    550\u001b[0m     inner_namespace \u001b[38;5;241m=\u001b[39m VarLookupDict([data, memorize_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m call_and_wrap_exc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError evaluating factor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    552\u001b[0m                              \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    553\u001b[0m                              memorize_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_env\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39meval,\n\u001b[1;32m    554\u001b[0m                              code,\n\u001b[1;32m    555\u001b[0m                              inner_namespace\u001b[38;5;241m=\u001b[39minner_namespace)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/patsy/compat.py:43\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     new_exc \u001b[38;5;241m=\u001b[39m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m                          \u001b[38;5;241m%\u001b[39m (msg, e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e),\n\u001b[1;32m     41\u001b[0m                          origin)\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     exec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise new_exc from e\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# In python 2, we just let the original exception escape -- better\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# than destroying the traceback. But if it's a PatsyError, we can\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# at least set the origin properly.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, PatsyError):\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "\u001b[0;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'CountFacility' is not defined\n    Psychotic ~ CountLaws + CountFacility\n                            ^^^^^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "mh_issues = mh_laws_20_all.columns[3:8]\n",
    "\n",
    "reg_results = pd.DataFrame()\n",
    "columns=['Intercept', 'CountLaws', 'CountFacility']\n",
    "\n",
    "for group in [mh_laws_20_all, mh_laws_20_youth, mh_laws_20_adult]:\n",
    "    for issue in list(mh_issues):\n",
    "        arg = issue + ' ~ CountLaws + CountFacility'\n",
    "        outcome, predictors = patsy.dmatrices(arg, group)\n",
    "        mod = sm.OLS(outcome, predictors)  \n",
    "        res = mod.fit()\n",
    "        p_values = res.summary2().tables[1]['P>|t|']\n",
    "        p_values.index = [0, 1, 2]\n",
    "        p_values = pd.DataFrame(p_values).T\n",
    "        p_values.index = [issue + ' P>|t|']\n",
    "        params = pd.DataFrame(res.params).T\n",
    "        params.index = [issue + ' Values']\n",
    "        reg_results = pd.concat([reg_results, params])\n",
    "        reg_results = pd.concat([reg_results, p_values])\n",
    "reg_results.columns = columns\n",
    "reg_results.reset_index().rename({'index': 'Category'}, axis=1)\n",
    "\n",
    "results_all = reg_results.iloc[:10].T\n",
    "results_youth = reg_results.iloc[10:20].T\n",
    "results_adults = reg_results.iloc[20:].T\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f7faa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_youth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363f6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty21 = pd.read_csv(\"poverty21.csv\")\n",
    "poverty22 = pd.read_csv(\"poverty22.csv\")\n",
    "\n",
    "poverty21['Label (Grouping)'] += \" (2021)\"\n",
    "poverty22['Label (Grouping)'] += \" (2022)\"\n",
    "# Combine the data from both years\n",
    "combined_data = pd.concat([poverty21, poverty22])\n",
    "\n",
    "# Extract state names from column names\n",
    "state_names = [col.split('!!')[0] for col in combined_data.columns if '!!' in col]\n",
    "\n",
    "# Rename columns with state names\n",
    "new_column_names = {}\n",
    "seen_states = set()\n",
    "for col in combined_data.columns[::-1]:  # Reverse order to keep the last occurrence\n",
    "    if '!!' in col:\n",
    "        state_name = col.split('!!')[0]\n",
    "        if state_name not in seen_states:\n",
    "            seen_states.add(state_name)\n",
    "            new_column_names[col] = state_name\n",
    "        else:\n",
    "            combined_data.drop(columns=[col], inplace=True)  # Remove entire column\n",
    "\n",
    "combined_data.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "combined_data.to_csv(\"cleaned_poverty_data.csv\", index=False)\n",
    "\n",
    "# Extracting relevant columns (States and Age groups population)\n",
    "age_data = combined_data.iloc[[2, 6, 10], 1:]\n",
    "\n",
    "# Converting data to numeric, replacing commas, and setting data types\n",
    "age_data = age_data.replace('%', '', regex=True).replace(',', '', regex=True).astype(float)\n",
    "\n",
    "# Transpose the dataframe for easy plotting\n",
    "age_data_transposed = age_data.transpose()\n",
    "age_data_transposed = age_data_transposed.reset_index()\n",
    "age_data_transposed = age_data_transposed[(age_data_transposed['index'] != 'Puerto Rico') & (age_data_transposed['index'] != 'District of Columbia')]\n",
    "age_data_transposed = age_data_transposed.set_index('index')\n",
    "age_data_transposed = age_data_transposed.rename({2: 'Youth (<18)', 6: 'Adults (18-65)', 10: 'Seniors (65+)'}, axis=1)\n",
    "age_data_transposed = age_data_transposed.reset_index().rename({'index': 'State'}, axis=1)\n",
    "age_data_transposed = age_data_transposed[age_data_transposed['State'].apply(keep_state)].iloc[1:]\n",
    "\n",
    "\n",
    "# 2021 general population poverty rates\n",
    "gen_pov = combined_data.T[0].iloc[1:]\n",
    "gen_pov_21 = pd.DataFrame(gen_pov.iloc[:, 0].str.replace('%', '').apply(float)).reset_index().rename({'index': 'State', 0: 'Poverty'}, axis=1)\n",
    "youth_pov_21 = age_data_transposed[['State', 'Youth (<18)']].rename({'Youth (<18)': 'Poverty'}, axis=1)\n",
    "adult_pov_21 = age_data_transposed[['State', 'Adults (18-65)']].rename({'Adults (18-65)': 'Poverty'}, axis=1)\n",
    "mh_laws_21_all = mh_laws_21_all.merge(gen_pov_21, on='State', how='left')\n",
    "mh_laws_21_youth = mh_laws_21_youth.merge(youth_pov_21, on='State', how='left')\n",
    "mh_laws_21_adult = mh_laws_21_adult.merge(adult_pov_21, on='State', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27378d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mh_issues = mh_laws_21_all.columns[3:8]\n",
    "\n",
    "reg_results = pd.DataFrame()\n",
    "columns=['Intercept', 'CountLaws', 'Poverty']\n",
    "\n",
    "mh_dfs = [mh_laws_21_all, mh_laws_21_youth, mh_laws_21_adult]\n",
    "\n",
    "for group in mh_dfs:\n",
    "    for issue in list(mh_issues):\n",
    "        arg = issue + ' ~ CountLaws + Poverty'\n",
    "        outcome, predictors = patsy.dmatrices(arg, group)\n",
    "        mod = sm.OLS(outcome, predictors)  \n",
    "        res = mod.fit()\n",
    "        p_values = res.summary2().tables[1]['P>|t|']\n",
    "        p_values.index = [0, 1, 2]\n",
    "        p_values = pd.DataFrame(p_values).T\n",
    "        p_values.index = [issue + ' P>|t|']\n",
    "        params = pd.DataFrame(res.params).T\n",
    "        params.index = [issue + ' Values']\n",
    "        reg_results = pd.concat([reg_results, params])\n",
    "        reg_results = pd.concat([reg_results, p_values])\n",
    "reg_results.columns = columns\n",
    "reg_results.reset_index().rename({'index': 'Category'}, axis=1)\n",
    "\n",
    "results_all = reg_results.iloc[:10].T\n",
    "results_youth = reg_results.iloc[10:20].T\n",
    "results_adults = reg_results.iloc[20:].T\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4128a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_youth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ad927",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_names = [col.split('!!')[0] for col in poverty22.columns if '!!' in col]\n",
    "\n",
    "# Rename columns with state names\n",
    "new_column_names = {}\n",
    "seen_states = set()\n",
    "for col in poverty22.columns[::-1]:  # Reverse order to keep the last occurrence\n",
    "    if '!!' in col:\n",
    "        state_name = col.split('!!')[0]\n",
    "        if state_name not in seen_states:\n",
    "            seen_states.add(state_name)\n",
    "            new_column_names[col] = state_name\n",
    "        else:\n",
    "            poverty22.drop(columns=[col], inplace=True)  # Remove entire column\n",
    "\n",
    "poverty22.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Extracting relevant columns (States and Age groups population)\n",
    "age_data = poverty22.iloc[[2, 6, 10], 1:]\n",
    "\n",
    "# Converting data to numeric, replacing commas, and setting data types\n",
    "age_data = age_data.replace('%', '', regex=True).replace(',', '', regex=True).astype(float)\n",
    "\n",
    "# Transpose the dataframe for easy plotting\n",
    "age_data_transposed = age_data.transpose()\n",
    "age_data_transposed = age_data_transposed.reset_index()\n",
    "age_data_transposed = age_data_transposed[(age_data_transposed['index'] != 'Puerto Rico') & (age_data_transposed['index'] != 'District of Columbia')]\n",
    "age_data_transposed = age_data_transposed.set_index('index')\n",
    "age_data_transposed = age_data_transposed.rename({2: 'Youth (<18)', 6: 'Adults (18-65)', 10: 'Seniors (65+)'}, axis=1)\n",
    "age_data_transposed = age_data_transposed.reset_index().rename({'index': 'State'}, axis=1)\n",
    "age_data_transposed = age_data_transposed[age_data_transposed['State'].apply(keep_state)].iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd538c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_pov_22 = pd.DataFrame(gen_pov.iloc[:, 1].str.replace('%', '').apply(float)).reset_index().rename({'index': 'State', 0: 'Poverty'}, axis=1)\n",
    "youth_pov_22 = age_data_transposed[['State', 'Youth (<18)']].rename({'Youth (<18)': 'Poverty'}, axis=1)\n",
    "adult_pov_22 = age_data_transposed[['State', 'Adults (18-65)']].rename({'Adults (18-65)': 'Poverty'}, axis=1)\n",
    "mh_laws_22_all = mh_laws_22_all.merge(gen_pov_22, on='State', how='left')\n",
    "mh_laws_22_youth = mh_laws_22_youth.merge(youth_pov_22, on='State', how='left')\n",
    "mh_laws_22_adult = mh_laws_22_adult.merge(adult_pov_22, on='State', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ffc8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mh_issues = mh_laws_22_all.columns[3:8]\n",
    "\n",
    "reg_results = pd.DataFrame()\n",
    "columns=['Intercept', 'CountLaws', 'Poverty']\n",
    "\n",
    "mh_dfs = [mh_laws_22_all, mh_laws_22_youth, mh_laws_22_adult]\n",
    "\n",
    "for group in mh_dfs:\n",
    "    for issue in list(mh_issues):\n",
    "        arg = issue + ' ~ CountLaws + Poverty'\n",
    "        outcome, predictors = patsy.dmatrices(arg, group)\n",
    "        mod = sm.OLS(outcome, predictors)  \n",
    "        res = mod.fit()\n",
    "        p_values = res.summary2().tables[1]['P>|t|']\n",
    "        p_values.index = [0, 1, 2]\n",
    "        p_values = pd.DataFrame(p_values).T\n",
    "        p_values.index = [issue + ' P>|t|']\n",
    "        params = pd.DataFrame(res.params).T\n",
    "        params.index = [issue + ' Values']\n",
    "        reg_results = pd.concat([reg_results, params])\n",
    "        reg_results = pd.concat([reg_results, p_values])\n",
    "reg_results.columns = columns\n",
    "reg_results.reset_index().rename({'index': 'Category'}, axis=1)\n",
    "\n",
    "results_all = reg_results.iloc[:10].T\n",
    "results_youth = reg_results.iloc[10:20].T\n",
    "results_adults = reg_results.iloc[20:].T\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf52af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_youth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = pd.read_csv('HPSA Score Detail_Full Data_data.csv')\n",
    "\n",
    "def get_year(string):\n",
    "    components = string.split('/')\n",
    "    return int(components[2])\n",
    "\n",
    "hc['Last Update Date'] = hc['Last Update Date'].apply(get_year)\n",
    "hc = hc[(hc['Last Update Date'] == 2023) | (hc['Last Update Date'] == 2022) | (hc['Last Update Date'] == 2021) | (hc['Last Update Date'] == 2020)]\n",
    "hc = hc.sort_values(by=['State/Territory', 'Last Update Date'])\n",
    "hc = hc.rename({\n",
    "    'State/Territory': 'State',\n",
    "    'Last Update Date': 'Year',\n",
    "    'HPSA Score': 'HPSA'\n",
    "}, axis=1).drop(columns=['State V1', 'Image'])\n",
    "hc = hc[hc['Year'] == 2023]\n",
    "hc = hc.drop(columns='Year')\n",
    "hc = hc[['State', 'HPSA']].groupby(['State']).mean().reset_index()\n",
    "\n",
    "mh_laws_23_all = mh_laws_23_all.merge(hc, on='State', how='left')\n",
    "mh_laws_23_youth = mh_laws_23_youth.merge(hc, on='State', how='left')\n",
    "mh_laws_23_adult = mh_laws_23_adult.merge(hc, on='State', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e4d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mh_dfs = [mh_laws_23_all, mh_laws_23_youth, mh_laws_23_adult]\n",
    "\n",
    "mh_issues = mh_laws_22_all.columns[3:8]\n",
    "\n",
    "reg_results = pd.DataFrame()\n",
    "columns=['Intercept', 'CountLaws', 'HPSA']\n",
    "\n",
    "for group in mh_dfs:\n",
    "    for issue in list(mh_issues):\n",
    "        arg = issue + ' ~ CountLaws + HPSA'\n",
    "        outcome, predictors = patsy.dmatrices(arg, group)\n",
    "        mod = sm.OLS(outcome, predictors)  \n",
    "        res = mod.fit()\n",
    "        p_values = res.summary2().tables[1]['P>|t|']\n",
    "        p_values.index = [0, 1, 2]\n",
    "        p_values = pd.DataFrame(p_values).T\n",
    "        p_values.index = [issue + ' P>|t|']\n",
    "        params = pd.DataFrame(res.params).T\n",
    "        params.index = [issue + ' Values']\n",
    "        reg_results = pd.concat([reg_results, params])\n",
    "        reg_results = pd.concat([reg_results, p_values])\n",
    "reg_results.columns = columns\n",
    "reg_results.reset_index().rename({'index': 'Category'}, axis=1)\n",
    "\n",
    "results_all = reg_results.iloc[:10].T\n",
    "results_youth = reg_results.iloc[10:20].T\n",
    "results_adults = reg_results.iloc[20:].T\n",
    "results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed1782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_youth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23cdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_adults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922c6ba",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58359d",
   "metadata": {},
   "source": [
    "# -----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0683b",
   "metadata": {},
   "source": [
    "# IGNORE EVERYTHING PAST THIS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5230761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the kernel from executing further lines when restarting all at once\n",
    "raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecacf66e",
   "metadata": {},
   "source": [
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb389d74",
   "metadata": {},
   "source": [
    "# ------------------------------------ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a3040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_web = combined_web.drop(index = [1457, 1456])\n",
    "combined_web = combined_web[combined_web.columns[:7]]\n",
    "state_mapping = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "    'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri',\n",
    "    'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "#def get_year(string):\n",
    "#    if (string.isnan())\n",
    "#    components = string.split('/')\n",
    "#    return int(components[2])\n",
    "#combined_web['Status Date'] = combined_web['Status Date'].apply(get_year)\n",
    "#combined_web = combined_web.rename({'Status Date': 'Year'})\n",
    "\n",
    "combined_web['State'] = combined_web['State'].str.strip()\n",
    "combined_web['State'] = combined_web['State'].replace(state_mapping)\n",
    "combined_web['State'] = combined_web['State'].replace('New England', 'Nebraska')\n",
    "#whoever made this csv initially confused them for some reason? ig NE looks like new england\n",
    "combined_web = combined_web[combined_web['State'] != 'Data is current as of December 21 2023']\n",
    "combined_web = combined_web[combined_web['State'] != 'Data is current as of March 8 2024']\n",
    "anti_web_df =  combined_web[~combined_web['Issues'].astype(str).str.contains('LGBTQ Equality Bills')]\n",
    "anti_web_df =  anti_web_df[~anti_web_df['Issues'].astype(str).str.contains('good bills')]\n",
    "#anti_web_df['Status Date'] = pd.to_datetime(anti_web_df['Status Date'])\n",
    "\n",
    "excluding_duplicates = anti_web_df.groupby(['State'])[\"Bill Name\"].nunique()\n",
    "excluding_duplicates = excluding_duplicates.reset_index()\n",
    "#makes a df of the number of unique bills per state, so that there aren't repeats \n",
    "\n",
    "merged_df = pd.merge(combined_20_23, excluding_duplicates[['State', 'Bill Name']], on='State', how='left')\n",
    "merged_df = merged_df.rename(columns = {'Bill Name': 'NumberBills',\n",
    "                                       'Psychotic Episodes': 'Psychotic',\n",
    "                                       'Trauma Survivors': 'Trauma',\n",
    "                                       'Suicidal Ideation': 'SuicidalIdea',\n",
    "                                       'Severe Depression': 'Depression'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9561e45",
   "metadata": {},
   "source": [
    "# Across all years, no confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Depression ~ NumberBills', merged_df)\n",
    "mod = sm.OLS(outcome, predictors)  \n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf3c93",
   "metadata": {},
   "source": [
    "# Breaking down by years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d82e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = pd.read_csv('HPSA Score Detail_Full Data_data.csv')\n",
    "hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = pd.read_csv('HPSA Score Detail_Full Data_data.csv')\n",
    "\n",
    "def get_year(string):\n",
    "    components = string.split('/')\n",
    "    return int(components[2])\n",
    "\n",
    "hc['Last Update Date'] = hc['Last Update Date'].apply(get_year)\n",
    "hc = hc[(hc['Last Update Date'] == 2023) | (hc['Last Update Date'] == 2022) | (hc['Last Update Date'] == 2021) | (hc['Last Update Date'] == 2020)]\n",
    "hc = hc.sort_values(by=['State/Territory', 'Last Update Date'])\n",
    "hc = hc.rename({\n",
    "    'State/Territory': 'State',\n",
    "    'Last Update Date': 'Year'\n",
    "}, axis=1).drop(columns=['State V1', 'Image'])\n",
    "hc_grouped = hc.groupby(['State']).mean()\n",
    "hc_grouped = hc_grouped.drop(columns='Year')\n",
    "sns.histplot(data=hc_grouped, x='HPSA Score')\n",
    "hc_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79271104",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, hc_grouped.reset_index(), on='State', how='left')\n",
    "merged_df = merged_df.rename({'HPSA Score': 'HPSA'}, axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd74b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Depression ~ NumberBills + HPSA', merged_df)\n",
    "mod = sm.OLS(outcome, predictors)  \n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73511a17",
   "metadata": {},
   "source": [
    "# Combining across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_avg = merged_df.groupby('State').mean().drop(columns=['Year'])\n",
    "merged_df_avg = merged_df_avg.dropna(axis=0, subset='NumberBills')\n",
    "merged_df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20658604",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Depression ~ NumberBills + HPSA', merged_df_avg)\n",
    "mod = sm.OLS(outcome, predictors)  \n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc62016f",
   "metadata": {},
   "source": [
    "# adding mental health facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e90b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import csv \n",
    "facilities_df = pd.read_csv('mental_health_facilities.csv')\n",
    "\n",
    "#keep relevant columns\n",
    "keep_cols = ['LST', 'FACILITYTYPE', 'FOCUS', 'SRVC62', 'PAYASST', 'REVCHK1']\n",
    "facilities_df = facilities_df[keep_cols]\n",
    "facilities_df = facilities_df.rename(columns={'LST': 'State', 'FACILITYTYPE': 'Facility Type', 'FOCUS': 'Focus', 'PAYASST': 'Pay Assist', 'SRVC62': 'LGBTQ Treatment Program', 'REVCHK1': 'Accepts Cash Payment' })\n",
    "\n",
    "facility_type_mapping = {\n",
    "    1: 'Psychiatric hospital',\n",
    "    2: 'Separate inpatient unit',\n",
    "    3: 'Residential treatment center for children',\n",
    "    4: 'Residential treatment center for adults',\n",
    "    5: 'Other type of residential treatment facility',\n",
    "    6: 'Veterans Administration Medical Center',\n",
    "    7: 'Community Mental Health Center',\n",
    "    8: 'Certified Community Behaviorial Health Clinic',\n",
    "    9: 'Partial hospitalization/day treatment facility',\n",
    "    10: 'Outpatient mental health facility',\n",
    "    11: 'Multi-setting mental health facility',\n",
    "    12: 'Other'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'facility type' column\n",
    "facilities_df['Facility Type'] = facilities_df['Facility Type'].map(facility_type_mapping)\n",
    "\n",
    "\n",
    "focus_mapping = {\n",
    "    1: 'Mental health treatment',\n",
    "    3: 'Mental health and substance use treatment',\n",
    "    4: 'General heath care',\n",
    "    5: 'Other service focus'\n",
    "\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'focus' column\n",
    "facilities_df['Focus'] = facilities_df['Focus'].map(focus_mapping)\n",
    "\n",
    "#Drop any facilities that are have state code 'ZZ' because this means that the location is unknown\n",
    "facilities_df = facilities_df[~(facilities_df['State'] == 'ZZ')]\n",
    "facilities_df['State'] = facilities_df['State'].replace(state_mapping)\n",
    "facilities_df = facilities_df.rename({'LGBTQ Treatment Program': 'ProgLGBT'}, axis=1)\n",
    "facilities_df = pd.concat([facilities_df.groupby('State').count()[['Facility Type']], facilities_df.groupby('State').sum()[['ProgLGBT']]], axis=1)\n",
    "facilities_df = pd.concat([facilities_df, pd.DataFrame(combined_20_23.groupby('State').mean(numeric_only = True)['Total Population'])], axis=1)\n",
    "facilities_df = facilities_df.dropna(axis=0)\n",
    "facilities_df = facilities_df.rename({\n",
    "    'Facility Type': 'CountFacility'\n",
    "}, axis=1)\n",
    "facilities_df['CountFacility'] = facilities_df['CountFacility'] / facilities_df['Total Population'] * 100000\n",
    "facilities_df['ProgLGBT'] = facilities_df['ProgLGBT'] / facilities_df['Total Population'] * 100000\n",
    "facilities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3511b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_avg_3 = pd.merge(merged_df_avg, facilities_df.reset_index().drop(columns=['Total Population']), on='State', how='left')\n",
    "mg_avg_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051423c5",
   "metadata": {},
   "source": [
    "# As it stands: facility counts are pretty important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73377d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Depression ~ NumberBills + HPSA + CountFacility', mg_avg_3)\n",
    "mod = sm.OLS(outcome, predictors)  \n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd9fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('PTSD ~ NumberBills + HPSA + CountFacility', mg_avg_3)\n",
    "mod = sm.OLS(outcome, predictors)  \n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Trauma ~ NumberBills + HPSA + CountFacility', mg_avg_3)\n",
    "mod = sm.OLS(outcome, predictors)  \n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab481b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('SuicidalIdea ~ NumberBills + HPSA + CountFacility', mg_avg_3)\n",
    "mod = sm.OLS(outcome, predictors)  \n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54960eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Psychotic ~ NumberBills + HPSA + CountFacility', mg_avg_3)\n",
    "mod = sm.OLS(outcome, predictors)  \n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=mg_avg_3, x='CountFacility', y='Trauma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf531fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=mg_avg_3[mg_avg_3['State'] != 'Missouri'], x='NumberBills', y='PTSD')\n",
    "mg_avg_3[mg_avg_3['State'] != 'Missouri'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec910c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
